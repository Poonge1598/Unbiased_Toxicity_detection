{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "Toxicity_detection",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7569041,
          "sourceType": "datasetVersion",
          "datasetId": 4285710
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Poonge1598/Unbiased_Toxicity_detection/blob/main/Toxicity_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'data-bal:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4285710%2F7569041%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240303%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240303T153632Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0654771a3c88bf3815ca7226b50d7a7ecacb4a5ec45149f6a6e9e36b46402122504d818ea7f33aa55f89705365399ba9f5b348d4336273ad518b640e54a589d386dc5215163fe04eabf8affa4404d01e24de6ae5ec13ca1c768e2bf71045c8a15eb0dba64389cce86d9fce8211755dcb8354d7c9427ea2c056874da3b688ef54ca2a08d444c420c4f01848907d40401cee687ff8a2b248d0014c0fb8de228fc731cec2971fe5583c6513c19a4b13b4b77f9d8d87e73374fde92fa54112720a1bf2a6abe0ffb867b377f7135e60fdf0bece8aca4f488824eb2e458cdb3d2437d1180263572151cc9a9dae95f64aa30e01a3ff633cde240bfe1bb58e67acb5c2fa'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Gm8bebPF9bY9"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics --quiet"
      ],
      "metadata": {
        "id": "BzU1n_t29Wpp",
        "execution": {
          "iopub.status.busy": "2024-02-06T08:58:56.62792Z",
          "iopub.execute_input": "2024-02-06T08:58:56.628866Z",
          "iopub.status.idle": "2024-02-06T08:59:08.986976Z",
          "shell.execute_reply.started": "2024-02-06T08:58:56.628832Z",
          "shell.execute_reply": "2024-02-06T08:59:08.985836Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary packages\n",
        "import os\n",
        "import csv\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from tqdm.notebook import tqdm\n",
        "#from google.colab import drive\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from torchmetrics import AUROC, F1Score\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvz6Udib8myP",
        "outputId": "f1f5e761-9576-4d85-ce0d-c834b126c64e",
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:08.988889Z",
          "iopub.execute_input": "2024-02-06T08:59:08.989215Z",
          "iopub.status.idle": "2024-02-06T08:59:09.018678Z",
          "shell.execute_reply.started": "2024-02-06T08:59:08.989185Z",
          "shell.execute_reply": "2024-02-06T08:59:09.017805Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_dir = '/kaggle/input/data-bal'"
      ],
      "metadata": {
        "id": "KhlLeBBX9QnO",
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:09.019872Z",
          "iopub.execute_input": "2024-02-06T08:59:09.020222Z",
          "iopub.status.idle": "2024-02-06T08:59:09.028718Z",
          "shell.execute_reply.started": "2024-02-06T08:59:09.020188Z",
          "shell.execute_reply": "2024-02-06T08:59:09.027871Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54D5PDve9lam",
        "outputId": "a02f34b6-014b-4035-9209-e83ba284cd89",
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:09.03092Z",
          "iopub.execute_input": "2024-02-06T08:59:09.031694Z",
          "iopub.status.idle": "2024-02-06T08:59:09.040979Z",
          "shell.execute_reply.started": "2024-02-06T08:59:09.031662Z",
          "shell.execute_reply": "2024-02-06T08:59:09.04014Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<torch._C.Generator at 0x7a9c727b7370>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "glove_model = KeyedVectors.load(\"/kaggle/input/data-bal/glove-twitter-200.model\", mmap='r')\n"
      ],
      "metadata": {
        "id": "p2AUdVjieQlL",
        "execution": {
          "iopub.status.busy": "2024-02-06T08:54:16.932965Z",
          "iopub.execute_input": "2024-02-06T08:54:16.933298Z",
          "iopub.status.idle": "2024-02-06T08:54:34.213497Z",
          "shell.execute_reply.started": "2024-02-06T08:54:16.933257Z",
          "shell.execute_reply": "2024-02-06T08:54:34.212606Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T08:54:34.214858Z",
          "iopub.execute_input": "2024-02-06T08:54:34.215519Z",
          "iopub.status.idle": "2024-02-06T08:54:34.221558Z",
          "shell.execute_reply.started": "2024-02-06T08:54:34.215485Z",
          "shell.execute_reply": "2024-02-06T08:54:34.22065Z"
        },
        "trusted": true,
        "id": "paJwL90o9bZG",
        "outputId": "e25bd208-7cae-4b2b-8d01-bf1dc72cc608"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<gensim.models.keyedvectors.KeyedVectors at 0x7a9c7277bcd0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the vocab for embedding matrix"
      ],
      "metadata": {
        "id": "pFMmDhdP9bZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "# Initialize the SymSpell spell checker\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "\n",
        "# Load the dictionary\n",
        "sym_spell.load_dictionary('en-80k.txt', term_index=0, count_index=1)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-04T16:04:32.080185Z",
          "iopub.execute_input": "2024-02-04T16:04:32.080559Z",
          "iopub.status.idle": "2024-02-04T16:04:32.462724Z",
          "shell.execute_reply.started": "2024-02-04T16:04:32.080525Z",
          "shell.execute_reply": "2024-02-04T16:04:32.461325Z"
        },
        "trusted": true,
        "id": "Tlcz1Yf-9bZH",
        "outputId": "c1c296e5-01de-4d9f-e0b4-d0a592cd052a"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msymspellpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SymSpell, Verbosity\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize the SymSpell spell checker\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sym_spell \u001b[38;5;241m=\u001b[39m SymSpell(max_dictionary_edit_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, prefix_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'symspellpy'"
          ],
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'symspellpy'",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "misspell_dict = {\"aren't\": \"are not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\n",
        "                 \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
        "                 \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "                 \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\n",
        "                 \"i'd\": \"I had\", \"i'll\": \"I will\", \"i'm\": \"I am\", \"isn't\": \"is not\",\n",
        "                 \"it's\": \"it is\", \"it'll\": \"it will\", \"i've\": \"I have\", \"let's\": \"let us\",\n",
        "                 \"mightn't\": \"might not\", \"mustn't\": \"must not\", \"shan't\": \"shall not\",\n",
        "                 \"she'd\": \"she would\", \"she'll\": \"she will\", \"she's\": \"she is\",\n",
        "                 \"shouldn't\": \"should not\", \"that's\": \"that is\", \"there's\": \"there is\",\n",
        "                 \"they'd\": \"they would\", \"they'll\": \"they will\", \"they're\": \"they are\",\n",
        "                 \"they've\": \"they have\", \"we'd\": \"we would\", \"we're\": \"we are\",\n",
        "                 \"weren't\": \"were not\", \"we've\": \"we have\", \"what'll\": \"what will\",\n",
        "                 \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
        "                 \"where's\": \"where is\", \"who'd\": \"who would\", \"who'll\": \"who will\",\n",
        "                 \"who're\": \"who are\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "                 \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n",
        "                 \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\",\n",
        "                 \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\": \" will\", \"tryin'\": \"trying\"}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:42.558194Z",
          "iopub.execute_input": "2024-02-06T08:59:42.559283Z",
          "iopub.status.idle": "2024-02-06T08:59:42.568142Z",
          "shell.execute_reply.started": "2024-02-06T08:59:42.55924Z",
          "shell.execute_reply": "2024-02-06T08:59:42.567306Z"
        },
        "trusted": true,
        "id": "mcx85piI9bZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']',\n",
        "          '>', '%', '=', '#', '*', '+', '\\\\', '•', '~', '@', '£', '·', '_', '{', '}', '©', '^',\n",
        "          '®', '`', '<', '→', '°', '€', '™', '›', '♥', '←', '×', '§', '″', '′', 'Â', '█',\n",
        "          '½', 'à', '…', '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶',\n",
        "          '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼',\n",
        "          '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
        "          'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»', '，', '♪',\n",
        "          '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:42.982642Z",
          "iopub.execute_input": "2024-02-06T08:59:42.983327Z",
          "iopub.status.idle": "2024-02-06T08:59:42.991505Z",
          "shell.execute_reply.started": "2024-02-06T08:59:42.983296Z",
          "shell.execute_reply": "2024-02-06T08:59:42.990568Z"
        },
        "trusted": true,
        "id": "U_VMMn6b9bZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_misspell(misspell_dict):\n",
        "    misspell_re = re.compile('(%s)' % '|'.join(misspell_dict.keys()))\n",
        "    return misspell_dict, misspell_re\n",
        "\n",
        "\n",
        "def replace_typical_misspell(text):\n",
        "    misspellings, misspellings_re = _get_misspell(misspell_dict)\n",
        "\n",
        "    def replace(match):\n",
        "        return misspellings[match.group(0)]\n",
        "\n",
        "    return misspellings_re.sub(replace, text)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:43.395423Z",
          "iopub.execute_input": "2024-02-06T08:59:43.395802Z",
          "iopub.status.idle": "2024-02-06T08:59:43.40176Z",
          "shell.execute_reply.started": "2024-02-06T08:59:43.39577Z",
          "shell.execute_reply": "2024-02-06T08:59:43.40066Z"
        },
        "trusted": true,
        "id": "tpHGwROW9bZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "#from nltk.stem import WordNetLemmatizer\n",
        "#from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    # Convert text to string\n",
        "    text =str(text)\n",
        "\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    #Strip blank spaces\n",
        "    text=text.strip()\n",
        "\n",
        "    text=replace_typical_misspell(text)\n",
        "\n",
        "    # Initialize lemmatizer\n",
        "    #lemmatizer = WordNetLemmatizer()\n",
        "    #stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "    # Lemmatize and remove stopwords\n",
        "    #words = [lemmatizer.lemmatize(word) for word in text.split()]\n",
        "\n",
        "    for punct in puncts + list(string.punctuation):\n",
        "\n",
        "        if punct in text:\n",
        "            text = text.replace(punct, f' {punct} ')\n",
        "\n",
        "\n",
        "    #words=word_tokenize(text)\n",
        "\n",
        "\n",
        "\n",
        "    # Spell checking and correction\n",
        "    #corrected_words = []\n",
        "    #for word in words:\n",
        "    #    suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2, include_unknown=True)\n",
        "    #    corrected_word = suggestions[0].term if suggestions else word\n",
        "    #    corrected_words.append(corrected_word)\n",
        "\n",
        "    # Remove non-alphanumeric characters and filter out single-character words\n",
        "    #corrected_text = ' '.join(corrected_words)\n",
        "    #corrected_text = re.sub(r'[^\\w\\s]', ' ', corrected_text)\n",
        "    #final_words = [word for word in corrected_text.split() if len(word) > 1]\n",
        "\n",
        "    # Rejoin corrected text\n",
        "    #cleaned_text = ' '.join(final_words).strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:43.691958Z",
          "iopub.execute_input": "2024-02-06T08:59:43.692326Z",
          "iopub.status.idle": "2024-02-06T08:59:43.699661Z",
          "shell.execute_reply.started": "2024-02-06T08:59:43.692297Z",
          "shell.execute_reply": "2024-02-06T08:59:43.698688Z"
        },
        "trusted": true,
        "id": "5FOnETU49bZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = pd.read_csv(os.path.join(data_dir, 'train_x.csv'))\n",
        "train_y = pd.read_csv(os.path.join(data_dir, 'train_y.csv'))\n",
        "train_data = train_x.join(train_y)\n",
        "\n",
        "val_x = pd.read_csv(os.path.join(data_dir, 'val_x.csv'))\n",
        "val_y = pd.read_csv(os.path.join(data_dir, 'val_y.csv'))\n",
        "val_data = val_x.join(val_y)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:44.220534Z",
          "iopub.execute_input": "2024-02-06T08:59:44.221371Z",
          "iopub.status.idle": "2024-02-06T08:59:47.799395Z",
          "shell.execute_reply.started": "2024-02-06T08:59:44.221338Z",
          "shell.execute_reply": "2024-02-06T08:59:47.798484Z"
        },
        "trusted": true,
        "id": "E-m4EzSH9bZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ext_data = pd.read_csv(os.path.join(data_dir, 'ext_data.csv'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:47.801422Z",
          "iopub.execute_input": "2024-02-06T08:59:47.802026Z",
          "iopub.status.idle": "2024-02-06T08:59:48.687607Z",
          "shell.execute_reply.started": "2024-02-06T08:59:47.801988Z",
          "shell.execute_reply": "2024-02-06T08:59:48.686786Z"
        },
        "trusted": true,
        "id": "iUCNRFFX9bZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ext_data = ext_data.rename(columns = {\n",
        "\n",
        "    'other_religion' : 'other_religions'\n",
        "})\n",
        "\n",
        "req_Cols = ['string', 'male', 'female', 'LGBTQ', 'christian', 'muslim',\n",
        "       'other_religions', 'black', 'white', 'y']\n",
        "\n",
        "train_data = train_data[req_Cols]\n",
        "val_data = val_data[req_Cols]\n",
        "\n",
        "train_data = pd.concat([train_data , ext_data], ignore_index = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:48.688685Z",
          "iopub.execute_input": "2024-02-06T08:59:48.68901Z",
          "iopub.status.idle": "2024-02-06T08:59:48.739415Z",
          "shell.execute_reply.started": "2024-02-06T08:59:48.688984Z",
          "shell.execute_reply": "2024-02-06T08:59:48.738597Z"
        },
        "trusted": true,
        "id": "vPEp0vDz9bZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv(os.path.join(data_dir, 'test_x.csv'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:48.741304Z",
          "iopub.execute_input": "2024-02-06T08:59:48.741594Z",
          "iopub.status.idle": "2024-02-06T08:59:50.014613Z",
          "shell.execute_reply.started": "2024-02-06T08:59:48.74157Z",
          "shell.execute_reply": "2024-02-06T08:59:50.013807Z"
        },
        "trusted": true,
        "id": "5HLRAmvt9bZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['string'] = train_data['string'].apply(clean_text)\n",
        "val_data['string'] = val_data['string'].apply(clean_text)\n",
        "test_data['string'] = test_data['string'].apply(clean_text)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T08:59:50.015942Z",
          "iopub.execute_input": "2024-02-06T08:59:50.016641Z",
          "iopub.status.idle": "2024-02-06T09:00:32.482916Z",
          "shell.execute_reply.started": "2024-02-06T08:59:50.016607Z",
          "shell.execute_reply": "2024-02-06T09:00:32.481962Z"
        },
        "trusted": true,
        "id": "DD58KiFc9bZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data['string'].fillna('_##_').values\n",
        "X_test = test_data['string'].fillna('_##_').values\n",
        "X_VAL = val_data['string'].fillna('_##_').values"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:00:32.484077Z",
          "iopub.execute_input": "2024-02-06T09:00:32.484343Z",
          "iopub.status.idle": "2024-02-06T09:00:32.579157Z",
          "shell.execute_reply.started": "2024-02-06T09:00:32.484321Z",
          "shell.execute_reply": "2024-02-06T09:00:32.578262Z"
        },
        "trusted": true,
        "id": "_37hizQ39bZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "max_features = 100000\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "def build_vocab(texts, max_features):\n",
        "    counter = Counter()\n",
        "    for text in texts:\n",
        "        counter.update(text.split())\n",
        "\n",
        "    vocab = {\n",
        "        'token2id': {'<PAD>': 0, '<UNK>': max_features + 1},\n",
        "        'id2token': {}\n",
        "    }\n",
        "    vocab['token2id'].update(\n",
        "        {token: _id + 1 for _id, (token, count) in\n",
        "         enumerate(counter.most_common(max_features))})\n",
        "    vocab['id2token'] = {v: k for k, v in vocab['token2id'].items()}\n",
        "    return vocab\n",
        "\n",
        "def tokenize(texts, vocab, max_len):\n",
        "    pad_id = vocab['token2id']['<PAD>']  # ID for the <PAD> token\n",
        "    unk_id = vocab['token2id']['<UNK>']  # ID for the <UNK> token\n",
        "\n",
        "    def text2ids(text, token2id):\n",
        "        # Convert text to IDs, using <UNK> ID if the token isn't found\n",
        "        token_ids = [token2id.get(token, unk_id) for token in text.split()[:max_len]]\n",
        "\n",
        "        # Pad the sequences to the maximum length\n",
        "        token_ids += [pad_id] * (max_len - len(token_ids))\n",
        "        return token_ids\n",
        "\n",
        "    return [text2ids(text, vocab['token2id']) for text in texts]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:00:32.580262Z",
          "iopub.execute_input": "2024-02-06T09:00:32.580553Z",
          "iopub.status.idle": "2024-02-06T09:00:32.590032Z",
          "shell.execute_reply.started": "2024-02-06T09:00:32.580528Z",
          "shell.execute_reply": "2024-02-06T09:00:32.589064Z"
        },
        "trusted": true,
        "id": "YMsHUeE-9bZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab(chain(X_train, X_test, X_VAL), max_features)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:00:32.591348Z",
          "iopub.execute_input": "2024-02-06T09:00:32.592048Z",
          "iopub.status.idle": "2024-02-06T09:00:40.77467Z",
          "shell.execute_reply.started": "2024-02-06T09:00:32.592014Z",
          "shell.execute_reply": "2024-02-06T09:00:40.773898Z"
        },
        "trusted": true,
        "id": "TO0Jc_0z9bZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(tokenize(X_train, vocab, max_len=220))\n",
        "X_test = np.array(tokenize(X_test, vocab, max_len=220))\n",
        "X_val = np.array(tokenize(X_VAL, vocab, max_len=220))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:00:40.777583Z",
          "iopub.execute_input": "2024-02-06T09:00:40.77788Z",
          "iopub.status.idle": "2024-02-06T09:01:05.333527Z",
          "shell.execute_reply.started": "2024-02-06T09:00:40.777855Z",
          "shell.execute_reply": "2024-02-06T09:01:05.332764Z"
        },
        "trusted": true,
        "id": "Q348Ptxo9bZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:01:05.334708Z",
          "iopub.execute_input": "2024-02-06T09:01:05.334998Z",
          "iopub.status.idle": "2024-02-06T09:01:05.341325Z",
          "shell.execute_reply.started": "2024-02-06T09:01:05.334974Z",
          "shell.execute_reply": "2024-02-06T09:01:05.340404Z"
        },
        "trusted": true,
        "id": "foXwlPpC9bZO",
        "outputId": "6fb0db5c-5f64-4240-fd13-3e760b28a4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[101,  73, 126, ...,   0,   0,   0],\n       [585, 129,   1, ...,   0,   0,   0],\n       [ 15,  20,  51, ...,   0,   0,   0],\n       ...,\n       [ 14, 141,  29, ...,   0,   0,   0],\n       [ 14,   8,   6, ...,   0,   0,   0],\n       [ 72, 358, 475, ...,   0,   0,   0]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = [\"male\", \"female\", \"LGBTQ\", \"christian\", \"muslim\", \"other_religions\", \"black\", \"white\"]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:01:05.342353Z",
          "iopub.execute_input": "2024-02-06T09:01:05.34262Z",
          "iopub.status.idle": "2024-02-06T09:01:05.351427Z",
          "shell.execute_reply.started": "2024-02-06T09:01:05.342589Z",
          "shell.execute_reply": "2024-02-06T09:01:05.350534Z"
        },
        "trusted": true,
        "id": "wu_dIGNX9bZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import numpy as np\n",
        "\n",
        "ps = PorterStemmer()\n",
        "lc = LancasterStemmer()\n",
        "sb = SnowballStemmer('english')\n",
        "\n",
        "\n",
        "def load_embedding(embedding_path, word_index: dict, max_features: int, embed_size: int):\n",
        "\n",
        "    def get_coefs(word, *arr):\n",
        "        return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "    embeddings_index = dict(get_coefs(*o.strip().split(' ')) for o in open(embedding_path))\n",
        "\n",
        "    # word_index = tokenizer.word_index\n",
        "    nb_words = min(max_features + 2, len(word_index))\n",
        "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "\n",
        "    for key, i in word_index.items():\n",
        "        if key in embeddings_index.keys():\n",
        "            word = key\n",
        "            embedding_vector = embeddings_index[word]\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "                continue\n",
        "            word = key.lower()\n",
        "            embedding_vector = embeddings_index[word]\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "                continue\n",
        "            word = key.upper()\n",
        "            embedding_vector = embeddings_index[word]\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "                continue\n",
        "            word = key.capitalize()\n",
        "            embedding_vector = embeddings_index[word]\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "                continue\n",
        "            word = ps.stem(key)\n",
        "            embedding_vector = embeddings_index[word]\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "                continue\n",
        "            word = lc.stem(key)\n",
        "            embedding_vector = embeddings_index[word]\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "                continue\n",
        "            word = sb.stem(key)\n",
        "            embedding_vector = embeddings_index[word]\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "                continue\n",
        "\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:01:05.352546Z",
          "iopub.execute_input": "2024-02-06T09:01:05.352862Z",
          "iopub.status.idle": "2024-02-06T09:01:05.365588Z",
          "shell.execute_reply.started": "2024-02-06T09:01:05.352833Z",
          "shell.execute_reply": "2024-02-06T09:01:05.364788Z"
        },
        "trusted": true,
        "id": "-O5KkkL39bZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_GLOVE='/kaggle/input/data-bal/glove.840B.300d.txt'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:01:05.366918Z",
          "iopub.execute_input": "2024-02-06T09:01:05.367235Z",
          "iopub.status.idle": "2024-02-06T09:01:05.379563Z",
          "shell.execute_reply.started": "2024-02-06T09:01:05.367207Z",
          "shell.execute_reply": "2024-02-06T09:01:05.378674Z"
        },
        "trusted": true,
        "id": "PnDHWzyj9bZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embedding_matrix = load_embedding(EMBEDDING_GLOVE, vocab['token2id'], max_features=max_features, embed_size=300)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:01:05.380463Z",
          "iopub.execute_input": "2024-02-06T09:01:05.38071Z",
          "iopub.status.idle": "2024-02-06T09:04:37.046315Z",
          "shell.execute_reply.started": "2024-02-06T09:01:05.380679Z",
          "shell.execute_reply": "2024-02-06T09:04:37.045456Z"
        },
        "trusted": true,
        "id": "-da54DKy9bZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the embedding matrix to a binary .npy file\n",
        "np.save('embedding_matrix.npy', glove_embedding_matrix)\n",
        "\n",
        "# To later load the embedding matrix:\n",
        "# embedding_matrix = np.load('/mnt/data/embedding_matrix.npy')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:37.050864Z",
          "iopub.execute_input": "2024-02-06T09:04:37.051128Z",
          "iopub.status.idle": "2024-02-06T09:04:37.227848Z",
          "shell.execute_reply.started": "2024-02-06T09:04:37.051106Z",
          "shell.execute_reply": "2024-02-06T09:04:37.226964Z"
        },
        "trusted": true,
        "id": "0FsHkVba9bZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yu9YXiNp9bZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming embedding_matrix is your numpy array containing the embeddings\n",
        "num_zero_vectors = 0\n",
        "for i, vector in enumerate(glove_embedding_matrix):\n",
        "    if np.all(vector == 0):\n",
        "        num_zero_vectors += 1\n",
        "\n",
        "# Adjust for <PAD> and <UNK> if they are explicitly set to non-zero vectors\n",
        "# If you've set <UNK> to a random or specific non-zero vector, adjust the count as follows:\n",
        "# num_zero_vectors -= 1  # Adjust if <UNK> is not initialized to zero\n",
        "\n",
        "print(f\"Number of words not in GloVe model: {num_zero_vectors}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:37.229172Z",
          "iopub.execute_input": "2024-02-06T09:04:37.229485Z",
          "iopub.status.idle": "2024-02-06T09:04:38.083001Z",
          "shell.execute_reply.started": "2024-02-06T09:04:37.229457Z",
          "shell.execute_reply": "2024-02-06T09:04:38.081992Z"
        },
        "trusted": true,
        "id": "IzEkG2af9bZQ",
        "outputId": "369adfa5-7705-4c4d-aa80-f12e70570628"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of words not in GloVe model: 22295\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hbS_UimJ9bZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)"
      ],
      "metadata": {
        "id": "UYZEMhtjNePx",
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.084557Z",
          "iopub.execute_input": "2024-02-06T09:04:38.084968Z",
          "iopub.status.idle": "2024-02-06T09:04:38.137896Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.084935Z",
          "shell.execute_reply": "2024-02-06T09:04:38.136834Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "LlfkNMsyQcU6",
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.138952Z",
          "iopub.execute_input": "2024-02-06T09:04:38.139213Z",
          "iopub.status.idle": "2024-02-06T09:04:38.146705Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.139191Z",
          "shell.execute_reply": "2024-02-06T09:04:38.1459Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9Qp_ZKkQdY3",
        "outputId": "bb0d2f24-47b2-4701-eea6-3bec463bd2a5",
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.1477Z",
          "iopub.execute_input": "2024-02-06T09:04:38.147986Z",
          "iopub.status.idle": "2024-02-06T09:04:38.156931Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.147963Z",
          "shell.execute_reply": "2024-02-06T09:04:38.156112Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdXKdG9Q9bZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.157855Z",
          "iopub.execute_input": "2024-02-06T09:04:38.158084Z",
          "iopub.status.idle": "2024-02-06T09:04:38.17959Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.158064Z",
          "shell.execute_reply": "2024-02-06T09:04:38.178805Z"
        },
        "trusted": true,
        "id": "kue5Ua5I9bZT",
        "outputId": "bc57b345-c6eb-4550-b1fa-ba750aaa60f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                   string  male  female  \\\n0       even up here  .    .    .    .    .    .    . ...     0       0   \n1       blame men  .    there is always an excuse to b...     1       1   \n2       you have no business making any comments on th...     0       0   \n3         \"  let us get the black folks and the white ...     0       0   \n4       i guess the issue is people not willing to put...     0       0   \n...                                                   ...   ...     ...   \n329121  the conservative economics of expanded trade h...     0       0   \n329122  so when white supremacists erect confederate s...     0       0   \n329123  it really was not about the niqab  ,   was it ...     0       0   \n329124  it is of course normal and natural for eugene ...     0       0   \n329125  my thought exactly  .    the only people he ha...     1       0   \n\n        LGBTQ  christian  muslim  other_religions  black  white  y  \n0           0          0       0                0      1      0  1  \n1           0          0       0                0      0      0  1  \n2           0          0       0                0      0      0  1  \n3           0          0       0                0      1      1  1  \n4           0          0       0                0      0      0  1  \n...       ...        ...     ...              ...    ...    ... ..  \n329121      0          0       0                0      0      1  0  \n329122      0          0       0                0      0      1  0  \n329123      0          0       1                0      0      0  0  \n329124      0          0       0                0      0      1  0  \n329125      0          0       0                0      0      1  0  \n\n[329126 rows x 10 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>string</th>\n      <th>male</th>\n      <th>female</th>\n      <th>LGBTQ</th>\n      <th>christian</th>\n      <th>muslim</th>\n      <th>other_religions</th>\n      <th>black</th>\n      <th>white</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>even up here  .    .    .    .    .    .    . ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>blame men  .    there is always an excuse to b...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>you have no business making any comments on th...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"  let us get the black folks and the white ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i guess the issue is people not willing to put...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>329121</th>\n      <td>the conservative economics of expanded trade h...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>329122</th>\n      <td>so when white supremacists erect confederate s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>329123</th>\n      <td>it really was not about the niqab  ,   was it ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>329124</th>\n      <td>it is of course normal and natural for eugene ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>329125</th>\n      <td>my thought exactly  .    the only people he ha...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>329126 rows × 10 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.180556Z",
          "iopub.execute_input": "2024-02-06T09:04:38.180827Z",
          "iopub.status.idle": "2024-02-06T09:04:38.186129Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.180805Z",
          "shell.execute_reply": "2024-02-06T09:04:38.185268Z"
        },
        "trusted": true,
        "id": "WvUON-6p9bZT",
        "outputId": "362102f2-061c-492a-d8b0-6dc0c33ead98"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['male',\n 'female',\n 'LGBTQ',\n 'christian',\n 'muslim',\n 'other_religions',\n 'black',\n 'white']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data=train_data[categories+['y']].groupby('y').sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.18723Z",
          "iopub.execute_input": "2024-02-06T09:04:38.187503Z",
          "iopub.status.idle": "2024-02-06T09:04:38.214193Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.187482Z",
          "shell.execute_reply": "2024-02-06T09:04:38.213311Z"
        },
        "trusted": true,
        "id": "vKt8OvWE9bZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.219136Z",
          "iopub.execute_input": "2024-02-06T09:04:38.219401Z",
          "iopub.status.idle": "2024-02-06T09:04:38.228931Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.219379Z",
          "shell.execute_reply": "2024-02-06T09:04:38.22802Z"
        },
        "trusted": true,
        "id": "M-bGeA4g9bZU",
        "outputId": "327c9450-ac53-4758-9e93-37fb691c9ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "    male  female  LGBTQ  christian  muslim  other_religions  black  white\ny                                                                        \n0  32133   36905  14383      29516   27521             5557  17575  31208\n1   6053    6117   4270       3324    6099             1006   6190   9342",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>male</th>\n      <th>female</th>\n      <th>LGBTQ</th>\n      <th>christian</th>\n      <th>muslim</th>\n      <th>other_religions</th>\n      <th>black</th>\n      <th>white</th>\n    </tr>\n    <tr>\n      <th>y</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32133</td>\n      <td>36905</td>\n      <td>14383</td>\n      <td>29516</td>\n      <td>27521</td>\n      <td>5557</td>\n      <td>17575</td>\n      <td>31208</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6053</td>\n      <td>6117</td>\n      <td>4270</td>\n      <td>3324</td>\n      <td>6099</td>\n      <td>1006</td>\n      <td>6190</td>\n      <td>9342</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data=grouped_data.transpose()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.23012Z",
          "iopub.execute_input": "2024-02-06T09:04:38.230445Z",
          "iopub.status.idle": "2024-02-06T09:04:38.236526Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.230416Z",
          "shell.execute_reply": "2024-02-06T09:04:38.235613Z"
        },
        "trusted": true,
        "id": "sv20uRut9bZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.237795Z",
          "iopub.execute_input": "2024-02-06T09:04:38.238495Z",
          "iopub.status.idle": "2024-02-06T09:04:38.248893Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.238471Z",
          "shell.execute_reply": "2024-02-06T09:04:38.248068Z"
        },
        "trusted": true,
        "id": "2XTsSsBQ9bZW",
        "outputId": "d15af697-14e2-46ea-9905-dde1084e7f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 39,
          "output_type": "execute_result",
          "data": {
            "text/plain": "y                    0     1\nmale             32133  6053\nfemale           36905  6117\nLGBTQ            14383  4270\nchristian        29516  3324\nmuslim           27521  6099\nother_religions   5557  1006\nblack            17575  6190\nwhite            31208  9342",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>y</th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>male</th>\n      <td>32133</td>\n      <td>6053</td>\n    </tr>\n    <tr>\n      <th>female</th>\n      <td>36905</td>\n      <td>6117</td>\n    </tr>\n    <tr>\n      <th>LGBTQ</th>\n      <td>14383</td>\n      <td>4270</td>\n    </tr>\n    <tr>\n      <th>christian</th>\n      <td>29516</td>\n      <td>3324</td>\n    </tr>\n    <tr>\n      <th>muslim</th>\n      <td>27521</td>\n      <td>6099</td>\n    </tr>\n    <tr>\n      <th>other_religions</th>\n      <td>5557</td>\n      <td>1006</td>\n    </tr>\n    <tr>\n      <th>black</th>\n      <td>17575</td>\n      <td>6190</td>\n    </tr>\n    <tr>\n      <th>white</th>\n      <td>31208</td>\n      <td>9342</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data['weights']=(grouped_data[1]+grouped_data[0])/(grouped_data[0]-grouped_data[1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.249922Z",
          "iopub.execute_input": "2024-02-06T09:04:38.25017Z",
          "iopub.status.idle": "2024-02-06T09:04:38.25899Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.250148Z",
          "shell.execute_reply": "2024-02-06T09:04:38.257966Z"
        },
        "trusted": true,
        "id": "H1aiUO-K9bZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.26044Z",
          "iopub.execute_input": "2024-02-06T09:04:38.260689Z",
          "iopub.status.idle": "2024-02-06T09:04:38.273295Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.260667Z",
          "shell.execute_reply": "2024-02-06T09:04:38.272407Z"
        },
        "trusted": true,
        "id": "mwql6lf89bZW",
        "outputId": "768c511a-d0e2-488b-9e28-96dd4f4d9069"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "y                    0     1   weights\nmale             32133  6053  1.464187\nfemale           36905  6117  1.397363\nLGBTQ            14383  4270  1.844458\nchristian        29516  3324  1.253818\nmuslim           27521  6099  1.569415\nother_religions   5557  1006  1.442101\nblack            17575  6190  2.087396\nwhite            31208  9342  1.854477",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>y</th>\n      <th>0</th>\n      <th>1</th>\n      <th>weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>male</th>\n      <td>32133</td>\n      <td>6053</td>\n      <td>1.464187</td>\n    </tr>\n    <tr>\n      <th>female</th>\n      <td>36905</td>\n      <td>6117</td>\n      <td>1.397363</td>\n    </tr>\n    <tr>\n      <th>LGBTQ</th>\n      <td>14383</td>\n      <td>4270</td>\n      <td>1.844458</td>\n    </tr>\n    <tr>\n      <th>christian</th>\n      <td>29516</td>\n      <td>3324</td>\n      <td>1.253818</td>\n    </tr>\n    <tr>\n      <th>muslim</th>\n      <td>27521</td>\n      <td>6099</td>\n      <td>1.569415</td>\n    </tr>\n    <tr>\n      <th>other_religions</th>\n      <td>5557</td>\n      <td>1006</td>\n      <td>1.442101</td>\n    </tr>\n    <tr>\n      <th>black</th>\n      <td>17575</td>\n      <td>6190</td>\n      <td>2.087396</td>\n    </tr>\n    <tr>\n      <th>white</th>\n      <td>31208</td>\n      <td>9342</td>\n      <td>1.854477</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights={f'{i}_1':None for i in grouped_data.index}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.274444Z",
          "iopub.execute_input": "2024-02-06T09:04:38.27483Z",
          "iopub.status.idle": "2024-02-06T09:04:38.281293Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.274797Z",
          "shell.execute_reply": "2024-02-06T09:04:38.280525Z"
        },
        "trusted": true,
        "id": "gp3C7vqP9bZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.282373Z",
          "iopub.execute_input": "2024-02-06T09:04:38.283207Z",
          "iopub.status.idle": "2024-02-06T09:04:38.293416Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.283172Z",
          "shell.execute_reply": "2024-02-06T09:04:38.292642Z"
        },
        "trusted": true,
        "id": "fEJmwqI19bZY",
        "outputId": "4e048730-5dd8-46fa-9edf-b3f3d5157fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'male_1': None,\n 'female_1': None,\n 'LGBTQ_1': None,\n 'christian_1': None,\n 'muslim_1': None,\n 'other_religions_1': None,\n 'black_1': None,\n 'white_1': None}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_category=['black','white']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.294468Z",
          "iopub.execute_input": "2024-02-06T09:04:38.294738Z",
          "iopub.status.idle": "2024-02-06T09:04:38.300596Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.294706Z",
          "shell.execute_reply": "2024-02-06T09:04:38.299704Z"
        },
        "trusted": true,
        "id": "U1c2oIUS9bZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_category=['LGBTQ','muslim']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.30172Z",
          "iopub.execute_input": "2024-02-06T09:04:38.302221Z",
          "iopub.status.idle": "2024-02-06T09:04:38.30982Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.302196Z",
          "shell.execute_reply": "2024-02-06T09:04:38.309091Z"
        },
        "trusted": true,
        "id": "Y_kOhcia9bZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in grouped_data.index:\n",
        "    if i in main_category:\n",
        "        weights[f'{i}_1']=grouped_data.loc[i,'weights']*2\n",
        "        weights[f'{i}_0']=1\n",
        "    elif i in second_category:\n",
        "        weights[f'{i}_1']=grouped_data.loc[i,'weights']\n",
        "        weights[f'{i}_0']=1\n",
        "\n",
        "    else:\n",
        "        weights[f'{i}_1']=1\n",
        "        weights[f'{i}_0']=1\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.310938Z",
          "iopub.execute_input": "2024-02-06T09:04:38.311191Z",
          "iopub.status.idle": "2024-02-06T09:04:38.322861Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.31117Z",
          "shell.execute_reply": "2024-02-06T09:04:38.322054Z"
        },
        "trusted": true,
        "id": "aSiogRHk9bZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.323916Z",
          "iopub.execute_input": "2024-02-06T09:04:38.324606Z",
          "iopub.status.idle": "2024-02-06T09:04:38.333102Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.324578Z",
          "shell.execute_reply": "2024-02-06T09:04:38.332237Z"
        },
        "trusted": true,
        "id": "i6m3BjV19bZZ",
        "outputId": "450b8364-e366-4e0f-f6ad-ab04a1819445"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'male_1': 1,\n 'female_1': 1,\n 'LGBTQ_1': 1.8444576287946208,\n 'christian_1': 1,\n 'muslim_1': 1.569414620483615,\n 'other_religions_1': 1,\n 'black_1': 4.174791392182697,\n 'white_1': 3.7089545412969906,\n 'male_0': 1,\n 'female_0': 1,\n 'LGBTQ_0': 1,\n 'christian_0': 1,\n 'muslim_0': 1,\n 'other_religions_0': 1,\n 'black_0': 1,\n 'white_0': 1}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_male_toxic = (train_data['male'] > 0.5) & (train_data['y'] == 1)\n",
        "mask_female_toxic = (train_data['female'] > 0.5) & (train_data['y'] == 1)\n",
        "mask_LGBTQ_toxic = (train_data['LGBTQ'] > 0.5) & (train_data['y'] == 1)\n",
        "mask_christian_toxic = (train_data['christian'] > 0.5) & (train_data['y'] == 1)\n",
        "mask_muslim_toxic = (train_data['muslim'] > 0.5) & (train_data['y'] == 1)\n",
        "mask_other_religions_toxic = (train_data['other_religions'] > 0.5) & (train_data['y'] == 1)\n",
        "mask_black_toxic = (train_data['black'] > 0.5) & (train_data['y'] == 1)\n",
        "mask_white_toxic = (train_data['white'] > 0.5) & (train_data['y'] == 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.334094Z",
          "iopub.execute_input": "2024-02-06T09:04:38.334367Z",
          "iopub.status.idle": "2024-02-06T09:04:38.350406Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.334339Z",
          "shell.execute_reply": "2024-02-06T09:04:38.349755Z"
        },
        "trusted": true,
        "id": "M0ana2IE9bZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['weights'] = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.351264Z",
          "iopub.execute_input": "2024-02-06T09:04:38.351595Z",
          "iopub.status.idle": "2024-02-06T09:04:38.356094Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.351573Z",
          "shell.execute_reply": "2024-02-06T09:04:38.355181Z"
        },
        "trusted": true,
        "id": "moR-IgeW9bZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['weights'] = 1\n",
        "train_data.loc[mask_LGBTQ_toxic, 'weights'] += weights['LGBTQ_1']\n",
        "train_data.loc[mask_muslim_toxic, 'weights'] += weights['muslim_1']\n",
        "train_data.loc[mask_black_toxic, 'weights'] += weights['black_1']\n",
        "train_data.loc[mask_white_toxic, 'weights'] += weights['white_1']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.357198Z",
          "iopub.execute_input": "2024-02-06T09:04:38.357469Z",
          "iopub.status.idle": "2024-02-06T09:04:38.375921Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.357446Z",
          "shell.execute_reply": "2024-02-06T09:04:38.375056Z"
        },
        "trusted": true,
        "id": "9lKMYkq79bZa",
        "outputId": "3929fe55-e0b2-468d-b14e-c377ced55ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_35/991162300.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[2.84445763 2.84445763 2.84445763 ... 2.84445763 2.84445763 2.84445763]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  train_data.loc[mask_LGBTQ_toxic, 'weights'] += weights['LGBTQ_1']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.377285Z",
          "iopub.execute_input": "2024-02-06T09:04:38.377585Z",
          "iopub.status.idle": "2024-02-06T09:04:38.390984Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.37756Z",
          "shell.execute_reply": "2024-02-06T09:04:38.390134Z"
        },
        "trusted": true,
        "id": "frSy0Jra9bZb",
        "outputId": "7ebc4b7d-c6d9-4421-d40c-269f8ac8d5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 51,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                   string  male  female  \\\n0       even up here  .    .    .    .    .    .    . ...     0       0   \n1       blame men  .    there is always an excuse to b...     1       1   \n2       you have no business making any comments on th...     0       0   \n3         \"  let us get the black folks and the white ...     0       0   \n4       i guess the issue is people not willing to put...     0       0   \n...                                                   ...   ...     ...   \n329121  the conservative economics of expanded trade h...     0       0   \n329122  so when white supremacists erect confederate s...     0       0   \n329123  it really was not about the niqab  ,   was it ...     0       0   \n329124  it is of course normal and natural for eugene ...     0       0   \n329125  my thought exactly  .    the only people he ha...     1       0   \n\n        LGBTQ  christian  muslim  other_religions  black  white  y   weights  \n0           0          0       0                0      1      0  1  5.174791  \n1           0          0       0                0      0      0  1  1.000000  \n2           0          0       0                0      0      0  1  1.000000  \n3           0          0       0                0      1      1  1  8.883746  \n4           0          0       0                0      0      0  1  1.000000  \n...       ...        ...     ...              ...    ...    ... ..       ...  \n329121      0          0       0                0      0      1  0  1.000000  \n329122      0          0       0                0      0      1  0  1.000000  \n329123      0          0       1                0      0      0  0  1.000000  \n329124      0          0       0                0      0      1  0  1.000000  \n329125      0          0       0                0      0      1  0  1.000000  \n\n[329126 rows x 11 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>string</th>\n      <th>male</th>\n      <th>female</th>\n      <th>LGBTQ</th>\n      <th>christian</th>\n      <th>muslim</th>\n      <th>other_religions</th>\n      <th>black</th>\n      <th>white</th>\n      <th>y</th>\n      <th>weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>even up here  .    .    .    .    .    .    . ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>5.174791</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>blame men  .    there is always an excuse to b...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>you have no business making any comments on th...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"  let us get the black folks and the white ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8.883746</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i guess the issue is people not willing to put...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>329121</th>\n      <td>the conservative economics of expanded trade h...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>329122</th>\n      <td>so when white supremacists erect confederate s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>329123</th>\n      <td>it really was not about the niqab  ,   was it ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>329124</th>\n      <td>it is of course normal and natural for eugene ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>329125</th>\n      <td>my thought exactly  .    the only people he ha...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>329126 rows × 11 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data['weights'] = 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.392113Z",
          "iopub.execute_input": "2024-02-06T09:04:38.392663Z",
          "iopub.status.idle": "2024-02-06T09:04:38.399253Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.392632Z",
          "shell.execute_reply": "2024-02-06T09:04:38.39852Z"
        },
        "trusted": true,
        "id": "FHrI_cQK9bZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CommentDataset(Dataset):\n",
        "    def __init__(self, comments, labels):\n",
        "        self.comments = comments\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        comment = torch.tensor(self.comments[idx], dtype=torch.long)\n",
        "        label = torch.tensor(self.labels.loc[idx,'y'], dtype=torch.float)\n",
        "        weights = torch.tensor(self.labels.loc[idx,'weights'], dtype = torch.float)\n",
        "\n",
        "\n",
        "        return comment, label ,idx, weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.400266Z",
          "iopub.execute_input": "2024-02-06T09:04:38.401004Z",
          "iopub.status.idle": "2024-02-06T09:04:38.408914Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.400979Z",
          "shell.execute_reply": "2024-02-06T09:04:38.408095Z"
        },
        "trusted": true,
        "id": "3l3rnPUe9bZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "train_dataset = CommentDataset(X_train, train_data)  # Assuming train_labels is defined\n",
        "val_dataset = CommentDataset(X_val, val_data)  # Assuming val_labels is defined\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64  # Define your batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,pin_memory=True,num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size,pin_memory=True,num_workers=4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.409912Z",
          "iopub.execute_input": "2024-02-06T09:04:38.410164Z",
          "iopub.status.idle": "2024-02-06T09:04:38.419481Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.410142Z",
          "shell.execute_reply": "2024-02-06T09:04:38.418678Z"
        },
        "trusted": true,
        "id": "cSK3gpSr9bZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[22]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.42034Z",
          "iopub.execute_input": "2024-02-06T09:04:38.420574Z",
          "iopub.status.idle": "2024-02-06T09:04:38.528826Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.420553Z",
          "shell.execute_reply": "2024-02-06T09:04:38.527997Z"
        },
        "trusted": true,
        "id": "ZnpuYhsu9bZb",
        "outputId": "fc5ae1c2-8f4a-4f97-83c4-2ea268a65f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 55,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(tensor([  14,  545,   68,  186,  275,    1,    5,   14,  536,  134,  156, 1432,\n            3,   18,  104,    1,   95,   20,  222, 5426,   93,  433,  383,   13,\n          181,  156,    5, 1985,   13,   70,  222,   46, 1742,   26, 5887,  176,\n           30,  537,  225, 2657, 4879,   26, 1349,    3,   33,   70,  743,    4,\n         1986,  932,  101,  384,   55,   17,  218,   59, 5680, 2378, 6051,   10,\n         3143,   14,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0]),\n tensor(0.),\n 22,\n tensor(1.))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.529792Z",
          "iopub.execute_input": "2024-02-06T09:04:38.530044Z",
          "iopub.status.idle": "2024-02-06T09:04:38.535503Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.530022Z",
          "shell.execute_reply": "2024-02-06T09:04:38.534619Z"
        },
        "trusted": true,
        "id": "tNJxXlrl9bZc",
        "outputId": "c259605f-704e-4b8e-99e1-6e2dee333cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 56,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['male',\n 'female',\n 'LGBTQ',\n 'christian',\n 'muslim',\n 'other_religions',\n 'black',\n 'white']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.LSTM, nn.GRU)):\n",
        "            # Initialize weights for LSTM/GRU\n",
        "            for name, param in m.named_parameters():\n",
        "                if 'weight_ih' in name:\n",
        "                    torch.nn.init.xavier_uniform_(param.data)\n",
        "                elif 'weight_hh' in name:\n",
        "                    torch.nn.init.orthogonal_(param.data)\n",
        "                elif 'bias' in name:\n",
        "                    param.data.fill_(0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            # Initialize weights for linear layers\n",
        "            torch.nn.init.xavier_uniform_(m.weight)\n",
        "            m.bias.data.fill_(0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.536542Z",
          "iopub.execute_input": "2024-02-06T09:04:38.536899Z",
          "iopub.status.idle": "2024-02-06T09:04:38.543666Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.536876Z",
          "shell.execute_reply": "2024-02-06T09:04:38.542667Z"
        },
        "trusted": true,
        "id": "NMuDJzJg9bZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert hidden_dim % num_heads == 0, \"hidden_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = hidden_dim // num_heads\n",
        "\n",
        "        self.query = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.key = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.value = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # Linear projections in batch from input to query, key, and value vectors\n",
        "        query = self.query(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        key = self.key(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        value = self.value(x).view(batch_size, -1, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        energy = torch.matmul(query, key.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "        attention = F.softmax(energy, dim=-1)  # Using softmax to compute attention weights\n",
        "        out = torch.matmul(attention, value)\n",
        "\n",
        "        # Concatenate heads\n",
        "        out = out.transpose(1, 2).contiguous().view(batch_size, -1, self.hidden_dim)\n",
        "\n",
        "        # Final linear layer\n",
        "        out = self.fc_out(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.544914Z",
          "iopub.execute_input": "2024-02-06T09:04:38.545347Z",
          "iopub.status.idle": "2024-02-06T09:04:38.55627Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.545316Z",
          "shell.execute_reply": "2024-02-06T09:04:38.555469Z"
        },
        "trusted": true,
        "id": "KCVgyfTt9bZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GloVeClassifier_mul_att(nn.Module):\n",
        "    # Initialize the classifier with various hyperparameters.\n",
        "    def __init__(self, embedding_matrix: np.ndarray,hidden_dim=128, lstm_layers=2, gru_layers=1, dropout_rate_lstm=0, dropout_rate_gru=0, dropout_rate=0.1, embedding_dim=300, num_heads=8):\n",
        "\n",
        "        super(GloVeClassifier_mul_att, self).__init__()\n",
        "        self.embedding = nn.Embedding(*embedding_matrix.shape)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "\n",
        "        self.embedding_dropout = nn.Dropout2d(0.1)\n",
        "        # Bidirectional LSTM layer for capturing sequential information in both directions.\n",
        "        self.bidirectional_lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=lstm_layers, bidirectional=True, dropout=dropout_rate_lstm, batch_first=True)\n",
        "        # GRU layer to capture dependencies and handle vanishing gradient problem.\n",
        "        self.gru = nn.GRU(hidden_dim * 2, hidden_dim // 2, num_layers=gru_layers, bidirectional=True, dropout=dropout_rate_gru, batch_first=True)\n",
        "        # Multi-head attention mechanism for focusing on different parts of the sequence.\n",
        "        self.multihead_attention = MultiHeadAttention(hidden_dim , num_heads)\n",
        "\n",
        "        # Fully connected layers for classification.\n",
        "        self.fc1 = nn.Linear(hidden_dim, hidden_dim //2)\n",
        "        self.fc2 = nn.Linear(hidden_dim //2, 1)\n",
        "        #self.fc3 = nn.Linear(hidden_dim, 1)\n",
        "        # LeakyReLU activation function.\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.01)\n",
        "\n",
        "    # Define the forward pass of the network.\n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n",
        "        x, _ = self.bidirectional_lstm(h_embedding)  # LSTM processing\n",
        "        x, _ = self.gru(x)                 # GRU processing\n",
        "        x = self.multihead_attention(x)    # Apply multi-head attention\n",
        "        #x = self.multihead_attention(x)\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        x = self.leaky_relu(self.fc1(x))   # Fully connected layer with LeakyReLU\n",
        "        #x = self.leaky_relu(self.fc2(x))   # Another fully connected layer\n",
        "        x = self.fc2(x)\n",
        "        #x = x.view(-1)  # Reshape output to match target shape [batch_size]\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:04:38.557572Z",
          "iopub.execute_input": "2024-02-06T09:04:38.557931Z",
          "iopub.status.idle": "2024-02-06T09:04:38.571921Z",
          "shell.execute_reply.started": "2024-02-06T09:04:38.557887Z",
          "shell.execute_reply": "2024-02-06T09:04:38.571073Z"
        },
        "trusted": true,
        "id": "i55NbBnT9bZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "anXUo01W9bZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_size = 300\n",
        "maxlen=220\n",
        "\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.bias = bias\n",
        "        self.feature_dim = feature_dim\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "\n",
        "        weight = torch.zeros(feature_dim, 1)\n",
        "        nn.init.kaiming_uniform_(weight)\n",
        "        self.weight = nn.Parameter(weight)\n",
        "\n",
        "        if bias:\n",
        "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        feature_dim = self.feature_dim\n",
        "        step_dim = self.step_dim\n",
        "        eij = torch.mm(\n",
        "            x.contiguous().view(-1, feature_dim),\n",
        "            self.weight\n",
        "        ).view(-1, step_dim)\n",
        "\n",
        "        if self.bias:\n",
        "            eij = eij + self.b\n",
        "\n",
        "        eij = torch.tanh(eij)\n",
        "        a = torch.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a = a * mask\n",
        "\n",
        "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
        "\n",
        "        weighted_input = x * torch.unsqueeze(a, -1)\n",
        "        return torch.sum(weighted_input, 1)\n",
        "\n",
        "class Attention_Net(nn.Module):\n",
        "    def __init__(self, embedding_matrix: np.ndarray):\n",
        "        super(Attention_Net, self).__init__()\n",
        "        drp = 0.1\n",
        "        self.embedding = nn.Embedding(*embedding_matrix.shape)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "\n",
        "        self.embedding_dropout = nn.Dropout2d(0.1)\n",
        "        self.lstm = nn.LSTM(embed_size, 128, bidirectional=True, batch_first=True)\n",
        "        self.lstm2 = nn.GRU(128*2, 64, bidirectional=True, batch_first=True)\n",
        "\n",
        "        self.attention_layer = Attention(128, maxlen)\n",
        "\n",
        "        self.linear = nn.Linear(64*2 , 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.out = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n",
        "        h_lstm, _ = self.lstm(h_embedding)\n",
        "        h_lstm, _ = self.lstm2(h_lstm)\n",
        "        h_lstm_atten = self.attention_layer(h_lstm)\n",
        "        conc = self.relu(self.linear(h_lstm_atten))\n",
        "        out = self.out(conc)\n",
        "        return out\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-05T09:02:35.07304Z",
          "iopub.execute_input": "2024-02-05T09:02:35.073427Z",
          "iopub.status.idle": "2024-02-05T09:02:35.090177Z",
          "shell.execute_reply.started": "2024-02-05T09:02:35.073394Z",
          "shell.execute_reply": "2024-02-05T09:02:35.088997Z"
        },
        "trusted": true,
        "id": "dNWm98vw9bZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Attention_Net(glove_embedding_matrix)\n",
        "initialize_weights(model)\n",
        "model = nn.DataParallel(model).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "#custom_loss=WeightedBCELoss(weights=weights,pos_weight=pos_weight).to(device)\n",
        "#criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight).to(device)\n",
        "#criterion=nn.BCELoss()\n",
        "#metric = F1Score(task='binary').to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-05T10:47:09.040798Z",
          "iopub.execute_input": "2024-02-05T10:47:09.041178Z",
          "iopub.status.idle": "2024-02-05T10:47:09.079304Z",
          "shell.execute_reply.started": "2024-02-05T10:47:09.041147Z",
          "shell.execute_reply": "2024-02-05T10:47:09.078246Z"
        },
        "trusted": true,
        "id": "fzan_H1h9bZe",
        "outputId": "f68b444a-42f2-4154-d159-6ccd2edda36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[81], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAttention_Net\u001b[49m(glove_embedding_matrix)\n\u001b[1;32m      2\u001b[0m initialize_weights(model)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDataParallel(model)\u001b[38;5;241m.\u001b[39mto(device)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Attention_Net' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'Attention_Net' is not defined",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GloVeClassifier_mul_att(glove_embedding_matrix)\n",
        "initialize_weights(model)\n",
        "model = nn.DataParallel(model).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "#custom_loss=WeightedBCELoss(weights=weights,pos_weight=pos_weight).to(device)\n",
        "#criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight).to(device)\n",
        "#criterion=nn.BCELoss()\n",
        "#metric = F1Score(task='binary').to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:22:18.919368Z",
          "iopub.execute_input": "2024-02-06T09:22:18.920112Z",
          "iopub.status.idle": "2024-02-06T09:22:19.242407Z",
          "shell.execute_reply.started": "2024-02-06T09:22:18.920077Z",
          "shell.execute_reply": "2024-02-06T09:22:19.241628Z"
        },
        "trusted": true,
        "id": "SHzsW42U9bZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:22:19.293099Z",
          "iopub.execute_input": "2024-02-06T09:22:19.293609Z",
          "iopub.status.idle": "2024-02-06T09:22:19.298329Z",
          "shell.execute_reply.started": "2024-02-06T09:22:19.293581Z",
          "shell.execute_reply": "2024-02-06T09:22:19.297309Z"
        },
        "trusted": true,
        "id": "Y6kwM3S89bZf",
        "outputId": "08c2b987-4874-48d3-b59c-5ccbbf775ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "DataParallel(\n  (module): GloVeClassifier_mul_att(\n    (embedding): Embedding(100002, 300)\n    (embedding_dropout): Dropout2d(p=0.1, inplace=False)\n    (bidirectional_lstm): LSTM(300, 128, num_layers=2, batch_first=True, bidirectional=True)\n    (gru): GRU(256, 64, batch_first=True, bidirectional=True)\n    (multihead_attention): MultiHeadAttention(\n      (query): Linear(in_features=128, out_features=128, bias=True)\n      (key): Linear(in_features=128, out_features=128, bias=True)\n      (value): Linear(in_features=128, out_features=128, bias=True)\n      (fc_out): Linear(in_features=128, out_features=128, bias=True)\n    )\n    (fc1): Linear(in_features=128, out_features=64, bias=True)\n    (fc2): Linear(in_features=64, out_features=1, bias=True)\n    (leaky_relu): LeakyReLU(negative_slope=0.01)\n  )\n)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=10"
      ],
      "metadata": {
        "id": "Fr5tlIwNaHec",
        "execution": {
          "iopub.status.busy": "2024-02-06T09:22:21.62008Z",
          "iopub.execute_input": "2024-02-06T09:22:21.620723Z",
          "iopub.status.idle": "2024-02-06T09:22:21.624842Z",
          "shell.execute_reply.started": "2024-02-06T09:22:21.620692Z",
          "shell.execute_reply": "2024-02-06T09:22:21.623895Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics\n",
        "metric =torchmetrics.Accuracy(task='binary').to(device)"
      ],
      "metadata": {
        "id": "lYJWwrgLDG5C",
        "execution": {
          "iopub.status.busy": "2024-02-06T09:22:21.942629Z",
          "iopub.execute_input": "2024-02-06T09:22:21.943346Z",
          "iopub.status.idle": "2024-02-06T09:22:21.949317Z",
          "shell.execute_reply.started": "2024-02-06T09:22:21.943314Z",
          "shell.execute_reply": "2024-02-06T09:22:21.948253Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "\n",
        "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=num_epochs, T_mult=1, eta_min=0.0001)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:22:22.343956Z",
          "iopub.execute_input": "2024-02-06T09:22:22.344296Z",
          "iopub.status.idle": "2024-02-06T09:22:22.349403Z",
          "shell.execute_reply.started": "2024-02-06T09:22:22.34427Z",
          "shell.execute_reply": "2024-02-06T09:22:22.348464Z"
        },
        "trusted": true,
        "id": "NVreRweC9bZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_group_accuracies(prediction, y):\n",
        "    \"\"\"\n",
        "    Compute the accuracies for each group.\n",
        "    arguments:\n",
        "        prediction [pandas.DataFrame]: dataframe with 2 columns (index and pred)\n",
        "        y [pandas.DataFrame]: dataframe containing the metadata\n",
        "    returns:\n",
        "        accuracies_dict [dict]: dictionary of accuracies for each group\n",
        "        wga [float]: worst group accuracy\n",
        "    \"\"\"\n",
        "    y.loc[prediction.index, 'pred'] = prediction.pred\n",
        "\n",
        "    categories = ['male', 'female', 'LGBTQ', 'christian', 'muslim', 'other_religions', 'black', 'white']\n",
        "    accuracies = []\n",
        "    accuracies_dict = {}\n",
        "\n",
        "    for category in categories:\n",
        "        category_accuracies = []\n",
        "        for label in [0, 1]:\n",
        "            group = y.loc[y[category] == label]\n",
        "            group_accuracy = (group['y'] == (group['pred'] > 0.5)).mean()\n",
        "            category_accuracies.append(group_accuracy)\n",
        "            accuracies_dict[f\"{category}_{label}\"] = group_accuracy\n",
        "        accuracies.extend(category_accuracies)\n",
        "\n",
        "    wga = np.min(accuracies)\n",
        "    return accuracies_dict, wga\n"
      ],
      "metadata": {
        "id": "I2aXR27S9WoL",
        "execution": {
          "iopub.status.busy": "2024-02-06T09:22:22.98837Z",
          "iopub.execute_input": "2024-02-06T09:22:22.989359Z",
          "iopub.status.idle": "2024-02-06T09:22:22.997407Z",
          "shell.execute_reply.started": "2024-02-06T09:22:22.989317Z",
          "shell.execute_reply": "2024-02-06T09:22:22.996443Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training - model(Attention_Net)\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    metric.reset()\n",
        "\n",
        "    for x, y,idx,weights in tqdm(train_loader):\n",
        "        x, y = x.to(device), y.to(device).squeeze()\n",
        "        #print(weights)\n",
        "        weights=weights.to(device)\n",
        "        #print(x.shape,y.shape)\n",
        "        #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x).squeeze()\n",
        "        #print(outputs.shape)\n",
        "        #break\n",
        "        #print(f\"x shape: {x.shape}, y shape: {y.shape}, outputs shape: {outputs.shape}\")\n",
        "        #print(groups)\n",
        "        #break\n",
        "        #loss = custom_loss(outputs, y,groups)\n",
        "        loss = (F.binary_cross_entropy_with_logits(outputs,y, reduction='none') * weights ).mean()\n",
        "        loss.backward()\n",
        "        # Gradient clipping\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        #scheduler.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        #print(torch.sigmoid(outputs.squeeze()))\n",
        "        #print(y.int())\n",
        "        metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "    train_accuracy = metric.compute()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_train_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    metric.reset()\n",
        "    val_predictions = []\n",
        "    val_indices = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y,idx,weights in tqdm(val_loader):\n",
        "            x, y = x.to(device), y.to(device).squeeze()\n",
        "            #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "            outputs = model(x).squeeze()\n",
        "            val_loss += (F.binary_cross_entropy_with_logits(outputs, y, reduction='none') ).mean().item()\n",
        "            metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "            val_predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "            val_indices.extend(idx.numpy())\n",
        "\n",
        "    val_accuracy = metric.compute()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Format predictions for WGA calculation\n",
        "    val_pred_df = pd.DataFrame({'index': val_indices, 'pred': val_predictions}).set_index('index')\n",
        "\n",
        "    # Compute WGA\n",
        "    group_accuracies, wga = compute_group_accuracies(val_pred_df, val_loader.dataset.labels)  # Ensure val_metadata is defined and aligned\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Group Accuracies:\")\n",
        "    for group, accuracy in group_accuracies.items():\n",
        "        print(f\"  {group}: {accuracy:.4f}\")\n",
        "    print(f\"Validation WGA: {wga:.4f}\")\n",
        "\n",
        "    accuracies_list = [accuracy for group, accuracy in group_accuracies.items()]\n",
        "    median_accuracy = np.median(accuracies_list)\n",
        "    mean_accuracy = np.mean(accuracies_list)\n",
        "    print(f'median:{median_accuracy}')\n",
        "    print(f'mean:{mean_accuracy}')\n",
        "\n",
        "# Save the model if needed\n",
        "# torch.save(model.state_dict(), 'model_path.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:22:40.857846Z",
          "iopub.execute_input": "2024-02-06T09:22:40.858397Z",
          "iopub.status.idle": "2024-02-06T10:03:52.685463Z",
          "shell.execute_reply.started": "2024-02-06T09:22:40.858357Z",
          "shell.execute_reply": "2024-02-06T10:03:52.684408Z"
        },
        "trusted": true,
        "id": "4OoHvfa49bZi",
        "outputId": "b8289de4-944a-430a-c66e-849e32ec30ce",
        "colab": {
          "referenced_widgets": [
            "b52ab58293c84a06b1df954915c2ccde",
            "2fdec99d53d345febcc73a45518abb5c",
            "74a1ea593a0749aa96c1022824dc2613",
            "f937025ec03343608a070a0459f4ee25",
            "d93c7e527d1c415e9618d6e34b736299",
            "4835d0044b0b44f39a8505c2d4633400",
            "69d3c9e0edd24c84b9843ba7bf937a52",
            "b51e5149d96b4de4b7809282414e6b38",
            "b7911d6bea4f4d8fa96343c6203b3608",
            "f5f056f33f454b2c8be94e926fc58c4b",
            "7370326eb387427889017a137b7a68c1",
            "fbff9a0146724e72aa69e91bded1a9ce",
            "cc9db471f3174a9c80ee104ecb08098c",
            "f027c4c455524b16bfefaa0667511bba",
            "590c3242cc574e258bf040aabae71fc4",
            "52f704be8590422b900aff3867948d7d",
            "039d6acc241b49609944874239d58fdf",
            "408f84eb22e14294b2e98874acc0cfd8",
            "57cbd1d4d06a4599b3513d60c75373f0",
            "61d059879ed849c18acc793a0207506a"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b52ab58293c84a06b1df954915c2ccde"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Training Loss: 0.3901, Training Accuracy: 0.8680\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fdec99d53d345febcc73a45518abb5c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Validation Loss: 0.1998, Validation Accuracy: 0.9149\nEpoch 1/10, Group Accuracies:\n  male_0: 0.9181\n  male_1: 0.8873\n  female_0: 0.9181\n  female_1: 0.8932\n  LGBTQ_0: 0.9184\n  LGBTQ_1: 0.8085\n  christian_0: 0.9134\n  christian_1: 0.9284\n  muslim_0: 0.9197\n  muslim_1: 0.8171\n  other_religions_0: 0.9161\n  other_religions_1: 0.8600\n  black_0: 0.9237\n  black_1: 0.6834\n  white_0: 0.9279\n  white_1: 0.7227\nValidation WGA: 0.6834\nmedian:0.9147544783053343\nmean:0.8722592489675002\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74a1ea593a0749aa96c1022824dc2613"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 2/10, Training Loss: 0.3428, Training Accuracy: 0.8828\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f937025ec03343608a070a0459f4ee25"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 2/10, Validation Loss: 0.2068, Validation Accuracy: 0.9093\nEpoch 2/10, Group Accuracies:\n  male_0: 0.9124\n  male_1: 0.8833\n  female_0: 0.9122\n  female_1: 0.8900\n  LGBTQ_0: 0.9151\n  LGBTQ_1: 0.7364\n  christian_0: 0.9076\n  christian_1: 0.9246\n  muslim_0: 0.9157\n  muslim_1: 0.7777\n  other_religions_0: 0.9112\n  other_religions_1: 0.8256\n  black_0: 0.9201\n  black_1: 0.6253\n  white_0: 0.9246\n  white_1: 0.6829\nValidation WGA: 0.6253\nmedian:0.9093725084612561\nmean:0.8540441283779021\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d93c7e527d1c415e9618d6e34b736299"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 3/10, Training Loss: 0.3200, Training Accuracy: 0.8915\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4835d0044b0b44f39a8505c2d4633400"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 3/10, Validation Loss: 0.1992, Validation Accuracy: 0.9129\nEpoch 3/10, Group Accuracies:\n  male_0: 0.9163\n  male_1: 0.8842\n  female_0: 0.9164\n  female_1: 0.8892\n  LGBTQ_0: 0.9178\n  LGBTQ_1: 0.7666\n  christian_0: 0.9115\n  christian_1: 0.9253\n  muslim_0: 0.9186\n  muslim_1: 0.7953\n  other_religions_0: 0.9145\n  other_religions_1: 0.8398\n  black_0: 0.9225\n  black_1: 0.6586\n  white_0: 0.9269\n  white_1: 0.7060\nValidation WGA: 0.6586\nmedian:0.9130036261594732\nmean:0.8630845815162498\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69d3c9e0edd24c84b9843ba7bf937a52"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 4/10, Training Loss: 0.2954, Training Accuracy: 0.9005\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b51e5149d96b4de4b7809282414e6b38"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 4/10, Validation Loss: 0.1777, Validation Accuracy: 0.9252\nEpoch 4/10, Group Accuracies:\n  male_0: 0.9282\n  male_1: 0.8999\n  female_0: 0.9283\n  female_1: 0.9046\n  LGBTQ_0: 0.9287\n  LGBTQ_1: 0.8202\n  christian_0: 0.9246\n  christian_1: 0.9308\n  muslim_0: 0.9296\n  muslim_1: 0.8370\n  other_religions_0: 0.9265\n  other_religions_1: 0.8682\n  black_0: 0.9317\n  black_1: 0.7561\n  white_0: 0.9350\n  white_1: 0.7806\nValidation WGA: 0.7561\nmedian:0.9255591079632326\nmean:0.8893664216721048\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7911d6bea4f4d8fa96343c6203b3608"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 5/10, Training Loss: 0.2656, Training Accuracy: 0.9107\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5f056f33f454b2c8be94e926fc58c4b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 5/10, Validation Loss: 0.1815, Validation Accuracy: 0.9265\nEpoch 5/10, Group Accuracies:\n  male_0: 0.9294\n  male_1: 0.9022\n  female_0: 0.9295\n  female_1: 0.9065\n  LGBTQ_0: 0.9298\n  LGBTQ_1: 0.8264\n  christian_0: 0.9254\n  christian_1: 0.9360\n  muslim_0: 0.9301\n  muslim_1: 0.8526\n  other_religions_0: 0.9277\n  other_religions_1: 0.8712\n  black_0: 0.9319\n  black_1: 0.7851\n  white_0: 0.9354\n  white_1: 0.7946\nValidation WGA: 0.7851\nmedian:0.9265761544892721\nmean:0.8946116840775824\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7370326eb387427889017a137b7a68c1"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 6/10, Training Loss: 0.2348, Training Accuracy: 0.9225\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbff9a0146724e72aa69e91bded1a9ce"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 6/10, Validation Loss: 0.1891, Validation Accuracy: 0.9287\nEpoch 6/10, Group Accuracies:\n  male_0: 0.9318\n  male_1: 0.9022\n  female_0: 0.9324\n  female_1: 0.9039\n  LGBTQ_0: 0.9314\n  LGBTQ_1: 0.8463\n  christian_0: 0.9280\n  christian_1: 0.9347\n  muslim_0: 0.9320\n  muslim_1: 0.8597\n  other_religions_0: 0.9298\n  other_religions_1: 0.8763\n  black_0: 0.9332\n  black_1: 0.8087\n  white_0: 0.9365\n  white_1: 0.8134\nValidation WGA: 0.8087\nmedian:0.928908175999025\nmean:0.9000196390359905\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc9db471f3174a9c80ee104ecb08098c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 7/10, Training Loss: 0.2052, Training Accuracy: 0.9325\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f027c4c455524b16bfefaa0667511bba"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 7/10, Validation Loss: 0.1842, Validation Accuracy: 0.9299\nEpoch 7/10, Group Accuracies:\n  male_0: 0.9331\n  male_1: 0.9028\n  female_0: 0.9335\n  female_1: 0.9060\n  LGBTQ_0: 0.9326\n  LGBTQ_1: 0.8497\n  christian_0: 0.9296\n  christian_1: 0.9330\n  muslim_0: 0.9333\n  muslim_1: 0.8611\n  other_religions_0: 0.9313\n  other_religions_1: 0.8712\n  black_0: 0.9340\n  black_1: 0.8232\n  white_0: 0.9362\n  white_1: 0.8382\nValidation WGA: 0.8232\nmedian:0.9304331501661878\nmean:0.9030526364189642\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "590c3242cc574e258bf040aabae71fc4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 8/10, Training Loss: 0.1814, Training Accuracy: 0.9399\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52f704be8590422b900aff3867948d7d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 8/10, Validation Loss: 0.1903, Validation Accuracy: 0.9263\nEpoch 8/10, Group Accuracies:\n  male_0: 0.9294\n  male_1: 0.9001\n  female_0: 0.9298\n  female_1: 0.9029\n  LGBTQ_0: 0.9287\n  LGBTQ_1: 0.8524\n  christian_0: 0.9250\n  christian_1: 0.9378\n  muslim_0: 0.9288\n  muslim_1: 0.8754\n  other_religions_0: 0.9272\n  other_religions_1: 0.8844\n  black_0: 0.9311\n  black_1: 0.7990\n  white_0: 0.9336\n  white_1: 0.8179\nValidation WGA: 0.7990\nmedian:0.9260944269716931\nmean:0.9002176390365975\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "039d6acc241b49609944874239d58fdf"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 9/10, Training Loss: 0.1612, Training Accuracy: 0.9470\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "408f84eb22e14294b2e98874acc0cfd8"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 9/10, Validation Loss: 0.2009, Validation Accuracy: 0.9308\nEpoch 9/10, Group Accuracies:\n  male_0: 0.9331\n  male_1: 0.9108\n  female_0: 0.9340\n  female_1: 0.9092\n  LGBTQ_0: 0.9333\n  LGBTQ_1: 0.8552\n  christian_0: 0.9297\n  christian_1: 0.9407\n  muslim_0: 0.9332\n  muslim_1: 0.8815\n  other_religions_0: 0.9317\n  other_religions_1: 0.8915\n  black_0: 0.9348\n  black_1: 0.8257\n  white_0: 0.9364\n  white_1: 0.8483\nValidation WGA: 0.8257\nmedian:0.9306737162532579\nmean:0.908059588483695\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57cbd1d4d06a4599b3513d60c75373f0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 10/10, Training Loss: 0.1446, Training Accuracy: 0.9529\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61d059879ed849c18acc793a0207506a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 10/10, Validation Loss: 0.2195, Validation Accuracy: 0.9337\nEpoch 10/10, Group Accuracies:\n  male_0: 0.9366\n  male_1: 0.9093\n  female_0: 0.9373\n  female_1: 0.9094\n  LGBTQ_0: 0.9360\n  LGBTQ_1: 0.8655\n  christian_0: 0.9329\n  christian_1: 0.9407\n  muslim_0: 0.9353\n  muslim_1: 0.9009\n  other_religions_0: 0.9345\n  other_religions_1: 0.8986\n  black_0: 0.9366\n  black_1: 0.8565\n  white_0: 0.9376\n  white_1: 0.8758\nValidation WGA: 0.8565\nmedian:0.9336887309038858\nmean:0.9152168415138764\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model's state, optimizer's state, and scheduler's state to a file.\n",
        "torch.save({\n",
        "    'epoch': epoch,  # Current epoch number\n",
        "    'model_state_dict': model.module.state_dict(),  # State of the model\n",
        "    'optimizer_state_dict': optimizer.state_dict(),  # State of the optimizer\n",
        "    'loss': loss,  # Last recorded loss\n",
        "    'scheduler_state_dict': scheduler.state_dict()  # State of the scheduler\n",
        "}, 'glove_multi_head_attention_model_a.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:05:36.763297Z",
          "iopub.execute_input": "2024-02-06T10:05:36.764004Z",
          "iopub.status.idle": "2024-02-06T10:05:37.064609Z",
          "shell.execute_reply.started": "2024-02-06T10:05:36.763972Z",
          "shell.execute_reply": "2024-02-06T10:05:37.063731Z"
        },
        "trusted": true,
        "id": "lLtsuI2t9bZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    metric.reset()\n",
        "\n",
        "    for x, y,idx,weights in tqdm(train_loader):\n",
        "        x, y = x.to(device), y.to(device).squeeze()\n",
        "        #print(weights)\n",
        "        weights=weights.to(device)\n",
        "        #print(x.shape,y.shape)\n",
        "        #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x).squeeze()\n",
        "        #print(outputs.shape)\n",
        "        #break\n",
        "        #print(f\"x shape: {x.shape}, y shape: {y.shape}, outputs shape: {outputs.shape}\")\n",
        "        #print(groups)\n",
        "        #break\n",
        "        #loss = custom_loss(outputs, y,groups)\n",
        "        loss = (F.binary_cross_entropy_with_logits(outputs,y, reduction='none') * weights ).mean()\n",
        "        loss.backward()\n",
        "        # Gradient clipping\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        #scheduler.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        #print(torch.sigmoid(outputs.squeeze()))\n",
        "        #print(y.int())\n",
        "        metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "    train_accuracy = metric.compute()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_train_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    metric.reset()\n",
        "    val_predictions = []\n",
        "    val_indices = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y,idx,weights in tqdm(val_loader):\n",
        "            x, y = x.to(device), y.to(device).squeeze()\n",
        "            #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "            outputs = model(x).squeeze()\n",
        "            val_loss += (F.binary_cross_entropy_with_logits(outputs, y, reduction='none') ).mean().item()\n",
        "            metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "            val_predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "            val_indices.extend(idx.numpy())\n",
        "\n",
        "    val_accuracy = metric.compute()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Format predictions for WGA calculation\n",
        "    val_pred_df = pd.DataFrame({'index': val_indices, 'pred': val_predictions}).set_index('index')\n",
        "\n",
        "    # Compute WGA\n",
        "    group_accuracies, wga = compute_group_accuracies(val_pred_df, val_loader.dataset.labels)  # Ensure val_metadata is defined and aligned\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Group Accuracies:\")\n",
        "    for group, accuracy in group_accuracies.items():\n",
        "        print(f\"  {group}: {accuracy:.4f}\")\n",
        "    print(f\"Validation WGA: {wga:.4f}\")\n",
        "\n",
        "    accuracies_list = [accuracy for group, accuracy in group_accuracies.items()]\n",
        "    median_accuracy = np.median(accuracies_list)\n",
        "    mean_accuracy = np.mean(accuracies_list)\n",
        "    print(f'median:{median_accuracy}')\n",
        "    print(f'mean:{mean_accuracy}')\n",
        "\n",
        "# Save the model if needed\n",
        "# torch.save(model.state_dict(), 'model_path.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:05:45.232958Z",
          "iopub.execute_input": "2024-02-06T10:05:45.233584Z",
          "iopub.status.idle": "2024-02-06T10:26:21.225135Z",
          "shell.execute_reply.started": "2024-02-06T10:05:45.233554Z",
          "shell.execute_reply": "2024-02-06T10:26:21.223826Z"
        },
        "trusted": true,
        "id": "9S_RaSnc9bZj",
        "outputId": "da9d0f0b-eeb9-4e8e-cc31-a00a494a3de4",
        "colab": {
          "referenced_widgets": [
            "3df3f772a3a64c489290e0a3bcb5e7d7",
            "8ff3cecda4f84f62b7bc344a25b42371",
            "a4638e2703ba42189dcf82fb6ff561d9",
            "d13330deef2d45e6824dc0735630fa61",
            "8fc28493be6249789424179c145b7edd",
            "0315644ec2b64a3098a801c359a338a6",
            "b104b5477c3a4043ae8f7206f39d2692",
            "bef1d05daa154be2be789261d6aec081",
            "6f182e5fb6c84a5a9b09c1b53ffc1384",
            "a4e15fdd1b9f4f6389bb32a82c7d02b4"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3df3f772a3a64c489290e0a3bcb5e7d7"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Training Loss: 0.1313, Training Accuracy: 0.9583\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ff3cecda4f84f62b7bc344a25b42371"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Validation Loss: 0.2331, Validation Accuracy: 0.9254\nEpoch 1/10, Group Accuracies:\n  male_0: 0.9287\n  male_1: 0.8976\n  female_0: 0.9300\n  female_1: 0.8948\n  LGBTQ_0: 0.9273\n  LGBTQ_1: 0.8682\n  christian_0: 0.9243\n  christian_1: 0.9352\n  muslim_0: 0.9275\n  muslim_1: 0.8834\n  other_religions_0: 0.9262\n  other_religions_1: 0.8915\n  black_0: 0.9282\n  black_1: 0.8529\n  white_0: 0.9298\n  white_1: 0.8601\nValidation WGA: 0.8529\nmedian:0.9252417275358459\nmean:0.9066009053530012\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4638e2703ba42189dcf82fb6ff561d9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 2/10, Training Loss: 0.1200, Training Accuracy: 0.9625\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d13330deef2d45e6824dc0735630fa61"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 2/10, Validation Loss: 0.2424, Validation Accuracy: 0.9324\nEpoch 2/10, Group Accuracies:\n  male_0: 0.9349\n  male_1: 0.9110\n  female_0: 0.9362\n  female_1: 0.9071\n  LGBTQ_0: 0.9340\n  LGBTQ_1: 0.8847\n  christian_0: 0.9315\n  christian_1: 0.9409\n  muslim_0: 0.9337\n  muslim_1: 0.9062\n  other_religions_0: 0.9333\n  other_religions_1: 0.8925\n  black_0: 0.9351\n  black_1: 0.8602\n  white_0: 0.9361\n  white_1: 0.8776\nValidation WGA: 0.8602\nmedian:0.9323743512636111\nmean:0.9159342263066097\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fc28493be6249789424179c145b7edd"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 3/10, Training Loss: 0.1099, Training Accuracy: 0.9658\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0315644ec2b64a3098a801c359a338a6"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 3/10, Validation Loss: 0.2519, Validation Accuracy: 0.9291\nEpoch 3/10, Group Accuracies:\n  male_0: 0.9325\n  male_1: 0.9005\n  female_0: 0.9335\n  female_1: 0.8997\n  LGBTQ_0: 0.9308\n  LGBTQ_1: 0.8792\n  christian_0: 0.9280\n  christian_1: 0.9387\n  muslim_0: 0.9308\n  muslim_1: 0.8943\n  other_religions_0: 0.9299\n  other_religions_1: 0.8915\n  black_0: 0.9318\n  black_1: 0.8571\n  white_0: 0.9329\n  white_1: 0.8730\nValidation WGA: 0.8571\nmedian:0.9289893571194181\nmean:0.9115221897997731\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b104b5477c3a4043ae8f7206f39d2692"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 4/10, Training Loss: 0.1000, Training Accuracy: 0.9694\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bef1d05daa154be2be789261d6aec081"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 4/10, Validation Loss: 0.2744, Validation Accuracy: 0.9305\nEpoch 4/10, Group Accuracies:\n  male_0: 0.9332\n  male_1: 0.9077\n  female_0: 0.9346\n  female_1: 0.9032\n  LGBTQ_0: 0.9320\n  LGBTQ_1: 0.8881\n  christian_0: 0.9296\n  christian_1: 0.9393\n  muslim_0: 0.9317\n  muslim_1: 0.9076\n  other_religions_0: 0.9312\n  other_religions_1: 0.9026\n  black_0: 0.9326\n  black_1: 0.8765\n  white_0: 0.9336\n  white_1: 0.8859\nValidation WGA: 0.8765\nmedian:0.9303632827987927\nmean:0.9168401404455306\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f182e5fb6c84a5a9b09c1b53ffc1384"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 5/10, Training Loss: 0.0923, Training Accuracy: 0.9724\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4e15fdd1b9f4f6389bb32a82c7d02b4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 5/10, Validation Loss: 0.2800, Validation Accuracy: 0.9289\nEpoch 5/10, Group Accuracies:\n  male_0: 0.9317\n  male_1: 0.9047\n  female_0: 0.9331\n  female_1: 0.9009\n  LGBTQ_0: 0.9304\n  LGBTQ_1: 0.8840\n  christian_0: 0.9278\n  christian_1: 0.9385\n  muslim_0: 0.9302\n  muslim_1: 0.9019\n  other_religions_0: 0.9298\n  other_religions_1: 0.8864\n  black_0: 0.9312\n  black_1: 0.8674\n  white_0: 0.9322\n  white_1: 0.8800\nValidation WGA: 0.8674\nmedian:0.9288220327551165\nmean:0.9131420123731123\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model's state, optimizer's state, and scheduler's state to a file.\n",
        "torch.save({\n",
        "    'epoch': epoch,  # Current epoch number\n",
        "    'model_state_dict': model.module.state_dict(),  # State of the model\n",
        "    'optimizer_state_dict': optimizer.state_dict(),  # State of the optimizer\n",
        "    'loss': loss,  # Last recorded loss\n",
        "    'scheduler_state_dict': scheduler.state_dict()  # State of the scheduler\n",
        "}, 'glove_multi_head_attention_model_a_5.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:27:57.314797Z",
          "iopub.execute_input": "2024-02-06T10:27:57.315783Z",
          "iopub.status.idle": "2024-02-06T10:27:57.541834Z",
          "shell.execute_reply.started": "2024-02-06T10:27:57.315716Z",
          "shell.execute_reply": "2024-02-06T10:27:57.541048Z"
        },
        "trusted": true,
        "id": "SSgABNLO9bZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    metric.reset()\n",
        "\n",
        "    for x, y,idx,weights in tqdm(train_loader):\n",
        "        x, y = x.to(device), y.to(device).squeeze()\n",
        "        #print(weights)\n",
        "        weights=weights.to(device)\n",
        "        #print(x.shape,y.shape)\n",
        "        #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x).squeeze()\n",
        "        #print(outputs.shape)\n",
        "        #break\n",
        "        #print(f\"x shape: {x.shape}, y shape: {y.shape}, outputs shape: {outputs.shape}\")\n",
        "        #print(groups)\n",
        "        #break\n",
        "        #loss = custom_loss(outputs, y,groups)\n",
        "        loss = (F.binary_cross_entropy_with_logits(outputs,y, reduction='none') * weights ).mean()\n",
        "        loss.backward()\n",
        "        # Gradient clipping\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        #scheduler.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        #print(torch.sigmoid(outputs.squeeze()))\n",
        "        #print(y.int())\n",
        "        metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "    train_accuracy = metric.compute()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_train_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    metric.reset()\n",
        "    val_predictions = []\n",
        "    val_indices = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y,idx,weights in tqdm(val_loader):\n",
        "            x, y = x.to(device), y.to(device).squeeze()\n",
        "            #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "            outputs = model(x).squeeze()\n",
        "            val_loss += (F.binary_cross_entropy_with_logits(outputs, y, reduction='none') ).mean().item()\n",
        "            metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "            val_predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "            val_indices.extend(idx.numpy())\n",
        "\n",
        "    val_accuracy = metric.compute()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Format predictions for WGA calculation\n",
        "    val_pred_df = pd.DataFrame({'index': val_indices, 'pred': val_predictions}).set_index('index')\n",
        "\n",
        "    # Compute WGA\n",
        "    group_accuracies, wga = compute_group_accuracies(val_pred_df, val_loader.dataset.labels)  # Ensure val_metadata is defined and aligned\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Group Accuracies:\")\n",
        "    for group, accuracy in group_accuracies.items():\n",
        "        print(f\"  {group}: {accuracy:.4f}\")\n",
        "    print(f\"Validation WGA: {wga:.4f}\")\n",
        "\n",
        "    accuracies_list = [accuracy for group, accuracy in group_accuracies.items()]\n",
        "    median_accuracy = np.median(accuracies_list)\n",
        "    mean_accuracy = np.mean(accuracies_list)\n",
        "    print(f'median:{median_accuracy}')\n",
        "    print(f'mean:{mean_accuracy}')\n",
        "\n",
        "# Save the model if needed\n",
        "# torch.save(model.state_dict(), 'model_path.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:28:02.744134Z",
          "iopub.execute_input": "2024-02-06T10:28:02.744494Z",
          "iopub.status.idle": "2024-02-06T10:32:09.869645Z",
          "shell.execute_reply.started": "2024-02-06T10:28:02.744464Z",
          "shell.execute_reply": "2024-02-06T10:32:09.868443Z"
        },
        "trusted": true,
        "id": "qgmIMmXS9bZo",
        "outputId": "bf205f2d-cd8a-4c56-e8f7-ac399968de48",
        "colab": {
          "referenced_widgets": [
            "35fb45fc65254511b7600e653f12f3b2",
            "b4334995a79045e1816f219a15c5fc2a"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35fb45fc65254511b7600e653f12f3b2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Training Loss: 0.0866, Training Accuracy: 0.9744\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4334995a79045e1816f219a15c5fc2a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Validation Loss: 0.2946, Validation Accuracy: 0.9309\nEpoch 1/10, Group Accuracies:\n  male_0: 0.9339\n  male_1: 0.9060\n  female_0: 0.9348\n  female_1: 0.9054\n  LGBTQ_0: 0.9325\n  LGBTQ_1: 0.8854\n  christian_0: 0.9299\n  christian_1: 0.9402\n  muslim_0: 0.9326\n  muslim_1: 0.8981\n  other_religions_0: 0.9318\n  other_religions_1: 0.8915\n  black_0: 0.9330\n  black_1: 0.8759\n  white_0: 0.9342\n  white_1: 0.8835\nValidation WGA: 0.8759\nmedian:0.9308636681235558\nmean:0.9155378894564121\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model's state, optimizer's state, and scheduler's state to a file.\n",
        "torch.save({\n",
        "    'epoch': epoch,  # Current epoch number\n",
        "    'model_state_dict': model.module.state_dict(),  # State of the model\n",
        "    'optimizer_state_dict': optimizer.state_dict(),  # State of the optimizer\n",
        "    'loss': loss,  # Last recorded loss\n",
        "    'scheduler_state_dict': scheduler.state_dict()  # State of the scheduler\n",
        "}, 'glove_multi_head_attention_model_a_6.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:39:04.617951Z",
          "iopub.execute_input": "2024-02-06T10:39:04.618797Z",
          "iopub.status.idle": "2024-02-06T10:39:04.844999Z",
          "shell.execute_reply.started": "2024-02-06T10:39:04.618733Z",
          "shell.execute_reply": "2024-02-06T10:39:04.844187Z"
        },
        "trusted": true,
        "id": "KZRJEp2a9bZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, comments):\n",
        "        self.comments = comments\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        comment = torch.tensor(self.comments[idx], dtype=torch.long)\n",
        "        return comment\n",
        "\n",
        "# Create datasets\n",
        "test_dataset = TestDataset(X_test)  # Assuming train_labels is defined\n",
        "# Create data loaders\n",
        "batch_size = 32  # Define your batch size\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:34:56.852661Z",
          "iopub.execute_input": "2024-02-06T10:34:56.853191Z",
          "iopub.status.idle": "2024-02-06T10:34:56.861107Z",
          "shell.execute_reply.started": "2024-02-06T10:34:56.853153Z",
          "shell.execute_reply": "2024-02-06T10:34:56.86001Z"
        },
        "trusted": true,
        "id": "t2i6OrEZ9bZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_predictions = []\n",
        "with torch.no_grad():\n",
        "    test_iterator = tqdm(test_loader, desc='Testing', dynamic_ncols=True)\n",
        "    for comments in test_iterator:\n",
        "\n",
        "        comments = comments.to(device)\n",
        "\n",
        "        outputs = model(comments)\n",
        "\n",
        "\n",
        "        probs = torch.sigmoid(outputs)  # Convert logits to probabilities\n",
        "        predicted_labels = (probs > 0.5).float()  # Convert probabilities to predicted class (0 or 1)\n",
        "\n",
        "        test_predictions.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
        "\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'ID': list(test_data.index),  # This should align with the index of your 'y' DataFrame\n",
        "        'pred': test_predictions.squeeze()  # Make sure this is a 1D array\n",
        "            })"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:35:12.765765Z",
          "iopub.execute_input": "2024-02-06T10:35:12.766567Z",
          "iopub.status.idle": "2024-02-06T10:36:23.136058Z",
          "shell.execute_reply.started": "2024-02-06T10:35:12.766535Z",
          "shell.execute_reply": "2024-02-06T10:36:23.135115Z"
        },
        "trusted": true,
        "id": "SaVIHQmA9bZr",
        "outputId": "f6c2bcdc-4e65-4595-bbf3-e6730e63e08a",
        "colab": {
          "referenced_widgets": [
            "fa84c4e6356a42a18569630bd7663ec0"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Testing:   0%|          | 0/4181 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa84c4e6356a42a18569630bd7663ec0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['preds'] = predictions_df['pred']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:36:59.484288Z",
          "iopub.execute_input": "2024-02-06T10:36:59.485009Z",
          "iopub.status.idle": "2024-02-06T10:36:59.490112Z",
          "shell.execute_reply.started": "2024-02-06T10:36:59.484976Z",
          "shell.execute_reply": "2024-02-06T10:36:59.489107Z"
        },
        "trusted": true,
        "id": "IQQopycM9bZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:37:07.148229Z",
          "iopub.execute_input": "2024-02-06T10:37:07.14861Z",
          "iopub.status.idle": "2024-02-06T10:37:07.161957Z",
          "shell.execute_reply.started": "2024-02-06T10:37:07.14858Z",
          "shell.execute_reply": "2024-02-06T10:37:07.16099Z"
        },
        "trusted": true,
        "id": "G_w2GVHt9bZs",
        "outputId": "522a2194-5426-4fb2-9712-5159a91ae02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 93,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         index                                             string  preds\n0            0  oh yes   -   were those evil christian mission...    0.0\n1            1  he is considered a good candidate for a cyber ...    0.0\n2            2  lela  ,   you admit no records exist to suppor...    0.0\n3            3  I will take the iffy libertarian over the guy ...    1.0\n4            4  should not your handle be republic of uranus  ?      0.0\n...        ...                                                ...    ...\n133777  133777  is it better to be dead  ,   and broke  ?   al...    0.0\n133778  133778  when you say speaking in code  ,   you are add...    0.0\n133779  133779  at least twice trained law enforcement officer...    0.0\n133780  133780  I have not said this before  ,   but kizla you...    1.0\n133781  133781  the democrat party aided and abetted by it is ...    1.0\n\n[133782 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>string</th>\n      <th>preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh yes   -   were those evil christian mission...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>he is considered a good candidate for a cyber ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>lela  ,   you admit no records exist to suppor...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>I will take the iffy libertarian over the guy ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>should not your handle be republic of uranus  ?</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>133777</th>\n      <td>133777</td>\n      <td>is it better to be dead  ,   and broke  ?   al...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133778</th>\n      <td>133778</td>\n      <td>when you say speaking in code  ,   you are add...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133779</th>\n      <td>133779</td>\n      <td>at least twice trained law enforcement officer...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133780</th>\n      <td>133780</td>\n      <td>I have not said this before  ,   but kizla you...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>133781</th>\n      <td>133781</td>\n      <td>the democrat party aided and abetted by it is ...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>133782 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.to_csv('weighted_multi_head_attention_new.csv',index = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:37:12.412043Z",
          "iopub.execute_input": "2024-02-06T10:37:12.412423Z",
          "iopub.status.idle": "2024-02-06T10:37:12.61186Z",
          "shell.execute_reply.started": "2024-02-06T10:37:12.412393Z",
          "shell.execute_reply": "2024-02-06T10:37:12.61105Z"
        },
        "trusted": true,
        "id": "ctEOhMhi9bZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-head GLove_att - training it on whole data - second attempt\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    metric.reset()\n",
        "\n",
        "    for x, y,idx,weights in tqdm(train_loader):\n",
        "        x, y = x.to(device), y.to(device).squeeze()\n",
        "        #print(weights)\n",
        "        weights=weights.to(device)\n",
        "        #print(x.shape,y.shape)\n",
        "        #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x).squeeze()\n",
        "        #print(outputs.shape)\n",
        "        #break\n",
        "        #print(f\"x shape: {x.shape}, y shape: {y.shape}, outputs shape: {outputs.shape}\")\n",
        "        #print(groups)\n",
        "        #break\n",
        "        #loss = custom_loss(outputs, y,groups)\n",
        "        loss = (F.binary_cross_entropy_with_logits(outputs,y, reduction='none') * weights ).mean()\n",
        "        loss.backward()\n",
        "        # Gradient clipping\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        #scheduler.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        #print(torch.sigmoid(outputs.squeeze()))\n",
        "        #print(y.int())\n",
        "        metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "    train_accuracy = metric.compute()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_train_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    metric.reset()\n",
        "    val_predictions = []\n",
        "    val_indices = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y,idx,weights in tqdm(val_loader):\n",
        "            x, y = x.to(device), y.to(device).squeeze()\n",
        "            #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "            outputs = model(x).squeeze()\n",
        "            val_loss += (F.binary_cross_entropy_with_logits(outputs, y, reduction='none') ).mean().item()\n",
        "            metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "            val_predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "            val_indices.extend(idx.numpy())\n",
        "\n",
        "    val_accuracy = metric.compute()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Format predictions for WGA calculation\n",
        "    val_pred_df = pd.DataFrame({'index': val_indices, 'pred': val_predictions}).set_index('index')\n",
        "\n",
        "    # Compute WGA\n",
        "    group_accuracies, wga = compute_group_accuracies(val_pred_df, val_loader.dataset.labels)  # Ensure val_metadata is defined and aligned\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Group Accuracies:\")\n",
        "    for group, accuracy in group_accuracies.items():\n",
        "        print(f\"  {group}: {accuracy:.4f}\")\n",
        "    print(f\"Validation WGA: {wga:.4f}\")\n",
        "\n",
        "    accuracies_list = [accuracy for group, accuracy in group_accuracies.items()]\n",
        "    median_accuracy = np.median(accuracies_list)\n",
        "    mean_accuracy = np.mean(accuracies_list)\n",
        "    print(f'median:{median_accuracy}')\n",
        "    print(f'mean:{mean_accuracy}')\n",
        "\n",
        "# Save the model if needed\n",
        "# torch.save(model.state_dict(), 'model_path.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T10:57:55.780363Z",
          "iopub.execute_input": "2024-02-06T10:57:55.780733Z",
          "iopub.status.idle": "2024-02-06T11:02:02.890641Z",
          "shell.execute_reply.started": "2024-02-06T10:57:55.780704Z",
          "shell.execute_reply": "2024-02-06T11:02:02.889395Z"
        },
        "trusted": true,
        "id": "37IfWTQu9bZs",
        "outputId": "b34a3b74-40ca-4636-cb5f-fe281f6a3ae6",
        "colab": {
          "referenced_widgets": [
            "228a3c56d9e1485ba02888d2f653c356",
            "90bc88d222d84fdc8964de85906bce32"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "228a3c56d9e1485ba02888d2f653c356"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Training Loss: 0.0739, Training Accuracy: 0.9789\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90bc88d222d84fdc8964de85906bce32"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Validation Loss: 0.3457, Validation Accuracy: 0.9311\nEpoch 1/10, Group Accuracies:\n  male_0: 0.9342\n  male_1: 0.9051\n  female_0: 0.9348\n  female_1: 0.9066\n  LGBTQ_0: 0.9323\n  LGBTQ_1: 0.8943\n  christian_0: 0.9300\n  christian_1: 0.9413\n  muslim_0: 0.9324\n  muslim_1: 0.9052\n  other_religions_0: 0.9318\n  other_religions_1: 0.8996\n  black_0: 0.9331\n  black_1: 0.8801\n  white_0: 0.9338\n  white_1: 0.8912\nValidation WGA: 0.8801\nmedian:0.9309005866566593\nmean:0.9178700760521801\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "luNY9mZt9bZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "izQrStHk9bZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second model(Multi-head GLove_att)"
      ],
      "metadata": {
        "id": "-HHvLVji9bZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Second model Multi-head GLove_att - training it on whole data - but with a bigger glove embedding - wiki\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    metric.reset()\n",
        "\n",
        "    for x, y,idx,weights in tqdm(train_loader):\n",
        "        x, y = x.to(device), y.to(device).squeeze()\n",
        "        #print(weights)\n",
        "        weights=weights.to(device)\n",
        "        #print(x.shape,y.shape)\n",
        "        #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x).squeeze()\n",
        "        #print(outputs.shape)\n",
        "        #break\n",
        "        #print(f\"x shape: {x.shape}, y shape: {y.shape}, outputs shape: {outputs.shape}\")\n",
        "        #print(groups)\n",
        "        #break\n",
        "        #loss = custom_loss(outputs, y,groups)\n",
        "        loss = (F.binary_cross_entropy_with_logits(outputs,y, reduction='none') * weights ).mean()\n",
        "        loss.backward()\n",
        "        # Gradient clipping\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        #scheduler.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        #print(torch.sigmoid(outputs.squeeze()))\n",
        "        #print(y.int())\n",
        "        metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "    train_accuracy = metric.compute()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_train_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    metric.reset()\n",
        "    val_predictions = []\n",
        "    val_indices = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y,idx,weights in tqdm(val_loader):\n",
        "            x, y = x.to(device), y.to(device).squeeze()\n",
        "            #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "            outputs = model(x).squeeze()\n",
        "            val_loss += (F.binary_cross_entropy_with_logits(outputs, y, reduction='none') ).mean().item()\n",
        "            metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "            val_predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "            val_indices.extend(idx.numpy())\n",
        "\n",
        "    val_accuracy = metric.compute()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Format predictions for WGA calculation\n",
        "    val_pred_df = pd.DataFrame({'index': val_indices, 'pred': val_predictions}).set_index('index')\n",
        "\n",
        "    # Compute WGA\n",
        "    group_accuracies, wga = compute_group_accuracies(val_pred_df, val_loader.dataset.labels)  # Ensure val_metadata is defined and aligned\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Group Accuracies:\")\n",
        "    for group, accuracy in group_accuracies.items():\n",
        "        print(f\"  {group}: {accuracy:.4f}\")\n",
        "    print(f\"Validation WGA: {wga:.4f}\")\n",
        "\n",
        "    accuracies_list = [accuracy for group, accuracy in group_accuracies.items()]\n",
        "    median_accuracy = np.median(accuracies_list)\n",
        "    mean_accuracy = np.mean(accuracies_list)\n",
        "    print(f'median:{median_accuracy}')\n",
        "    print(f'mean:{mean_accuracy}')\n",
        "\n",
        "# Save the model if needed\n",
        "# torch.save(model.state_dict(), 'model_path.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-05T13:30:54.555588Z",
          "iopub.execute_input": "2024-02-05T13:30:54.55596Z",
          "iopub.status.idle": "2024-02-05T14:14:00.522948Z",
          "shell.execute_reply.started": "2024-02-05T13:30:54.555929Z",
          "shell.execute_reply": "2024-02-05T14:14:00.521687Z"
        },
        "trusted": true,
        "id": "4aMyHciI9bZu",
        "outputId": "193b964a-8635-4be9-bcb9-4629ad090862",
        "colab": {
          "referenced_widgets": [
            "1494e9292c8945b68fff61d720ff028c",
            "077f8c3bf1874dc8aba3975beef02346",
            "10b7829c29534416937462eced79b750",
            "668a57a13f6e4734a7aa6085e86919c6",
            "5e4db7070f7145279e4b6967b408ac41",
            "5082abef581c400fade712b959343d99",
            "d0fc217264884a8da4cde285153aba8f",
            "c903073f15de4318a3d5aaf629263804",
            "1b562ca436314b6f994071b059b959d3",
            "4f686c64dc2242ed8ebef199cea40217",
            "21e2e8af458044bb82f6756e468981ea",
            "0484a6f824244ea1a264da16f10fe261",
            "f5cc306ef08340b7a4de7f8db671e3de",
            "5734645b93de4483ada72566ccd9b950",
            "5071833cceae43b78b32d504dfffd47b",
            "0b4ce95e7c4c413ab6a9b723dfd322f7",
            "e99c7de7456a4a179989811bf02e7d6f",
            "ca29cef47f1a4386818e6dd38f740feb",
            "176f8e8fd9b644758b1c701b3395c7d4",
            "ac78c9599a11401896a7c5262de38959"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1494e9292c8945b68fff61d720ff028c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Training Loss: 0.3915, Training Accuracy: 0.8699\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "077f8c3bf1874dc8aba3975beef02346"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Validation Loss: 0.1965, Validation Accuracy: 0.9128\nEpoch 1/10, Group Accuracies:\n  male_0: 0.9160\n  male_1: 0.8858\n  female_0: 0.9153\n  female_1: 0.8961\n  LGBTQ_0: 0.9175\n  LGBTQ_1: 0.7721\n  christian_0: 0.9112\n  christian_1: 0.9270\n  muslim_0: 0.9184\n  muslim_1: 0.7981\n  other_religions_0: 0.9139\n  other_religions_1: 0.8611\n  black_0: 0.9218\n  black_1: 0.6768\n  white_0: 0.9279\n  white_1: 0.6903\nValidation WGA: 0.6768\nmedian:0.9125731082021051\nmean:0.8655765378192575\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10b7829c29534416937462eced79b750"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 2/10, Training Loss: 0.3415, Training Accuracy: 0.8838\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "668a57a13f6e4734a7aa6085e86919c6"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 2/10, Validation Loss: 0.1973, Validation Accuracy: 0.9118\nEpoch 2/10, Group Accuracies:\n  male_0: 0.9159\n  male_1: 0.8772\n  female_0: 0.9149\n  female_1: 0.8914\n  LGBTQ_0: 0.9178\n  LGBTQ_1: 0.7316\n  christian_0: 0.9101\n  christian_1: 0.9266\n  muslim_0: 0.9164\n  muslim_1: 0.8180\n  other_religions_0: 0.9131\n  other_religions_1: 0.8540\n  black_0: 0.9231\n  black_1: 0.6138\n  white_0: 0.9270\n  white_1: 0.6878\nValidation WGA: 0.6138\nmedian:0.9116140199470237\nmean:0.8586657173761647\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e4db7070f7145279e4b6967b408ac41"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 3/10, Training Loss: 0.3203, Training Accuracy: 0.8909\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5082abef581c400fade712b959343d99"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 3/10, Validation Loss: 0.1878, Validation Accuracy: 0.9209\nEpoch 3/10, Group Accuracies:\n  male_0: 0.9237\n  male_1: 0.8974\n  female_0: 0.9231\n  female_1: 0.9061\n  LGBTQ_0: 0.9252\n  LGBTQ_1: 0.7927\n  christian_0: 0.9196\n  christian_1: 0.9325\n  muslim_0: 0.9256\n  muslim_1: 0.8256\n  other_religions_0: 0.9222\n  other_religions_1: 0.8631\n  black_0: 0.9291\n  black_1: 0.7064\n  white_0: 0.9331\n  white_1: 0.7408\nValidation WGA: 0.7064\nmedian:0.9209113408202403\nmean:0.8791431358553587\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0fc217264884a8da4cde285153aba8f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 4/10, Training Loss: 0.2958, Training Accuracy: 0.9002\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c903073f15de4318a3d5aaf629263804"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 4/10, Validation Loss: 0.1822, Validation Accuracy: 0.9240\nEpoch 4/10, Group Accuracies:\n  male_0: 0.9270\n  male_1: 0.8982\n  female_0: 0.9267\n  female_1: 0.9061\n  LGBTQ_0: 0.9283\n  LGBTQ_1: 0.7948\n  christian_0: 0.9227\n  christian_1: 0.9356\n  muslim_0: 0.9284\n  muslim_1: 0.8346\n  other_religions_0: 0.9253\n  other_religions_1: 0.8661\n  black_0: 0.9308\n  black_1: 0.7446\n  white_0: 0.9339\n  white_1: 0.7778\nValidation WGA: 0.7446\nmedian:0.9239882834406387\nmean:0.8863047264634654\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b562ca436314b6f994071b059b959d3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 5/10, Training Loss: 0.2668, Training Accuracy: 0.9103\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f686c64dc2242ed8ebef199cea40217"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 5/10, Validation Loss: 0.1856, Validation Accuracy: 0.9223\nEpoch 5/10, Group Accuracies:\n  male_0: 0.9248\n  male_1: 0.9005\n  female_0: 0.9253\n  female_1: 0.9022\n  LGBTQ_0: 0.9264\n  LGBTQ_1: 0.7982\n  christian_0: 0.9211\n  christian_1: 0.9327\n  muslim_0: 0.9262\n  muslim_1: 0.8417\n  other_religions_0: 0.9233\n  other_religions_1: 0.8742\n  black_0: 0.9289\n  black_1: 0.7464\n  white_0: 0.9322\n  white_1: 0.7754\nValidation WGA: 0.7464\nmedian:0.9222153991322198\nmean:0.8862316994187049\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21e2e8af458044bb82f6756e468981ea"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 6/10, Training Loss: 0.2356, Training Accuracy: 0.9213\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0484a6f824244ea1a264da16f10fe261"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 6/10, Validation Loss: 0.1848, Validation Accuracy: 0.9267\nEpoch 6/10, Group Accuracies:\n  male_0: 0.9297\n  male_1: 0.9018\n  female_0: 0.9300\n  female_1: 0.9049\n  LGBTQ_0: 0.9304\n  LGBTQ_1: 0.8174\n  christian_0: 0.9255\n  christian_1: 0.9371\n  muslim_0: 0.9303\n  muslim_1: 0.8531\n  other_religions_0: 0.9278\n  other_religions_1: 0.8783\n  black_0: 0.9316\n  black_1: 0.7978\n  white_0: 0.9341\n  white_1: 0.8179\nValidation WGA: 0.7978\nmedian:0.9266716266367726\nmean:0.8967360708065235\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5cc306ef08340b7a4de7f8db671e3de"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 7/10, Training Loss: 0.2078, Training Accuracy: 0.9309\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5734645b93de4483ada72566ccd9b950"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 7/10, Validation Loss: 0.1856, Validation Accuracy: 0.9305\nEpoch 7/10, Group Accuracies:\n  male_0: 0.9334\n  male_1: 0.9064\n  female_0: 0.9341\n  female_1: 0.9066\n  LGBTQ_0: 0.9336\n  LGBTQ_1: 0.8394\n  christian_0: 0.9295\n  christian_1: 0.9396\n  muslim_0: 0.9339\n  muslim_1: 0.8630\n  other_religions_0: 0.9314\n  other_religions_1: 0.8935\n  black_0: 0.9345\n  black_1: 0.8257\n  white_0: 0.9360\n  white_1: 0.8497\nValidation WGA: 0.8257\nmedian:0.9304528003980748\nmean:0.9056425119563145\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5071833cceae43b78b32d504dfffd47b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 8/10, Training Loss: 0.1829, Training Accuracy: 0.9396\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b4ce95e7c4c413ab6a9b723dfd322f7"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 8/10, Validation Loss: 0.1958, Validation Accuracy: 0.9236\nEpoch 8/10, Group Accuracies:\n  male_0: 0.9259\n  male_1: 0.9037\n  female_0: 0.9264\n  female_1: 0.9044\n  LGBTQ_0: 0.9259\n  LGBTQ_1: 0.8545\n  christian_0: 0.9221\n  christian_1: 0.9369\n  muslim_0: 0.9266\n  muslim_1: 0.8616\n  other_religions_0: 0.9245\n  other_religions_1: 0.8824\n  black_0: 0.9277\n  black_1: 0.8148\n  white_0: 0.9297\n  white_1: 0.8329\nValidation WGA: 0.8148\nmedian:0.9232846476431734\nmean:0.9000006812198735\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e99c7de7456a4a179989811bf02e7d6f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 9/10, Training Loss: 0.1637, Training Accuracy: 0.9454\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca29cef47f1a4386818e6dd38f740feb"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 9/10, Validation Loss: 0.2018, Validation Accuracy: 0.9296\nEpoch 9/10, Group Accuracies:\n  male_0: 0.9321\n  male_1: 0.9081\n  female_0: 0.9331\n  female_1: 0.9065\n  LGBTQ_0: 0.9320\n  LGBTQ_1: 0.8586\n  christian_0: 0.9280\n  christian_1: 0.9440\n  muslim_0: 0.9319\n  muslim_1: 0.8825\n  other_religions_0: 0.9303\n  other_religions_1: 0.8966\n  black_0: 0.9328\n  black_1: 0.8438\n  white_0: 0.9342\n  white_1: 0.8615\nValidation WGA: 0.8438\nmedian:0.9291570785649841\nmean:0.9097438696232636\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "176f8e8fd9b644758b1c701b3395c7d4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 10/10, Training Loss: 0.1462, Training Accuracy: 0.9518\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac78c9599a11401896a7c5262de38959"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 10/10, Validation Loss: 0.2249, Validation Accuracy: 0.9334\nEpoch 10/10, Group Accuracies:\n  male_0: 0.9363\n  male_1: 0.9093\n  female_0: 0.9366\n  female_1: 0.9119\n  LGBTQ_0: 0.9353\n  LGBTQ_1: 0.8778\n  christian_0: 0.9324\n  christian_1: 0.9426\n  muslim_0: 0.9354\n  muslim_1: 0.8924\n  other_religions_0: 0.9340\n  other_religions_1: 0.9097\n  black_0: 0.9362\n  black_1: 0.8596\n  white_0: 0.9377\n  white_1: 0.8702\nValidation WGA: 0.8596\nmedian:0.9331700848532032\nmean:0.9160971805250191\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model's state, optimizer's state, and scheduler's state to a file.\n",
        "torch.save({\n",
        "    'epoch': epoch,  # Current epoch number\n",
        "    'model_state_dict': model.module.state_dict(),  # State of the model\n",
        "    'optimizer_state_dict': optimizer.state_dict(),  # State of the optimizer\n",
        "    'loss': loss,  # Last recorded loss\n",
        "    'scheduler_state_dict': scheduler.state_dict()  # State of the scheduler\n",
        "}, 'glove_multi_head_attention_model.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-05T14:14:53.422608Z",
          "iopub.execute_input": "2024-02-05T14:14:53.423113Z",
          "iopub.status.idle": "2024-02-05T14:14:53.647993Z",
          "shell.execute_reply.started": "2024-02-05T14:14:53.423077Z",
          "shell.execute_reply": "2024-02-05T14:14:53.646993Z"
        },
        "trusted": true,
        "id": "Ep7BYXtT9bZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-head GLove_att - training it on whole data - but with a bigger glove embedding - wiki\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    metric.reset()\n",
        "\n",
        "    for x, y,idx,weights in tqdm(train_loader):\n",
        "        x, y = x.to(device), y.to(device).squeeze()\n",
        "        #print(weights)\n",
        "        weights=weights.to(device)\n",
        "        #print(x.shape,y.shape)\n",
        "        #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x).squeeze()\n",
        "        #print(outputs.shape)\n",
        "        #break\n",
        "        #print(f\"x shape: {x.shape}, y shape: {y.shape}, outputs shape: {outputs.shape}\")\n",
        "        #print(groups)\n",
        "        #break\n",
        "        #loss = custom_loss(outputs, y,groups)\n",
        "        loss = (F.binary_cross_entropy_with_logits(outputs,y, reduction='none') * weights ).mean()\n",
        "        loss.backward()\n",
        "        # Gradient clipping\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        #scheduler.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        #print(torch.sigmoid(outputs.squeeze()))\n",
        "        #print(y.int())\n",
        "        metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "    train_accuracy = metric.compute()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_train_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    metric.reset()\n",
        "    val_predictions = []\n",
        "    val_indices = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y,idx,weights in tqdm(val_loader):\n",
        "            x, y = x.to(device), y.to(device).squeeze()\n",
        "            #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "            outputs = model(x).squeeze()\n",
        "            val_loss += (F.binary_cross_entropy_with_logits(outputs, y, reduction='none') ).mean().item()\n",
        "            metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "            val_predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "            val_indices.extend(idx.numpy())\n",
        "\n",
        "    val_accuracy = metric.compute()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Format predictions for WGA calculation\n",
        "    val_pred_df = pd.DataFrame({'index': val_indices, 'pred': val_predictions}).set_index('index')\n",
        "\n",
        "    # Compute WGA\n",
        "    group_accuracies, wga = compute_group_accuracies(val_pred_df, val_loader.dataset.labels)  # Ensure val_metadata is defined and aligned\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Group Accuracies:\")\n",
        "    for group, accuracy in group_accuracies.items():\n",
        "        print(f\"  {group}: {accuracy:.4f}\")\n",
        "    print(f\"Validation WGA: {wga:.4f}\")\n",
        "\n",
        "    accuracies_list = [accuracy for group, accuracy in group_accuracies.items()]\n",
        "    median_accuracy = np.median(accuracies_list)\n",
        "    mean_accuracy = np.mean(accuracies_list)\n",
        "    print(f'median:{median_accuracy}')\n",
        "    print(f'mean:{mean_accuracy}')\n",
        "\n",
        "# Save the model if needed\n",
        "# torch.save(model.state_dict(), 'model_path.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-05T14:15:21.277672Z",
          "iopub.execute_input": "2024-02-05T14:15:21.278564Z",
          "iopub.status.idle": "2024-02-05T14:36:54.315101Z",
          "shell.execute_reply.started": "2024-02-05T14:15:21.278529Z",
          "shell.execute_reply": "2024-02-05T14:36:54.31392Z"
        },
        "trusted": true,
        "id": "8HdDNIVM9bZu",
        "outputId": "19353449-cf64-4aa8-9b2d-479ead342bfd",
        "colab": {
          "referenced_widgets": [
            "bc60c523861e46a0b8db6d1f7d11dd45",
            "270a3068f1604c8d961c83d100315082",
            "5888e197d0af41b2b46742363b094095",
            "ce4d1d43e168401b94a543a29791d3c3",
            "11d22bc6f19c4b9f8560978278ada600",
            "7e5fab9b2e5d4e329407deaffac76d4b",
            "315cd888e7fc4b80959273be817be4f2",
            "fd43f6155d6c4583aa645c8856e243d2",
            "1e00867388cf449d81316e9a28608f0e",
            "2a49430eb00741b182b82189e6ab01e7"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc60c523861e46a0b8db6d1f7d11dd45"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Training Loss: 0.1321, Training Accuracy: 0.9569\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "270a3068f1604c8d961c83d100315082"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Validation Loss: 0.2223, Validation Accuracy: 0.9268\nEpoch 1/10, Group Accuracies:\n  male_0: 0.9297\n  male_1: 0.9022\n  female_0: 0.9301\n  female_1: 0.9044\n  LGBTQ_0: 0.9291\n  LGBTQ_1: 0.8579\n  christian_0: 0.9257\n  christian_1: 0.9367\n  muslim_0: 0.9291\n  muslim_1: 0.8787\n  other_religions_0: 0.9276\n  other_religions_1: 0.8884\n  black_0: 0.9304\n  black_1: 0.8311\n  white_0: 0.9321\n  white_1: 0.8479\nValidation WGA: 0.8311\nmedian:0.9266539612542917\nmean:0.9050804451095609\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5888e197d0af41b2b46742363b094095"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 2/10, Training Loss: 0.1210, Training Accuracy: 0.9613\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce4d1d43e168401b94a543a29791d3c3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 2/10, Validation Loss: 0.2214, Validation Accuracy: 0.9317\nEpoch 2/10, Group Accuracies:\n  male_0: 0.9345\n  male_1: 0.9081\n  female_0: 0.9355\n  female_1: 0.9066\n  LGBTQ_0: 0.9333\n  LGBTQ_1: 0.8833\n  christian_0: 0.9305\n  christian_1: 0.9422\n  muslim_0: 0.9336\n  muslim_1: 0.8924\n  other_religions_0: 0.9324\n  other_religions_1: 0.9016\n  black_0: 0.9340\n  black_1: 0.8723\n  white_0: 0.9351\n  white_1: 0.8811\nValidation WGA: 0.8723\nmedian:0.9314428526380414\nmean:0.9160271856159266\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11d22bc6f19c4b9f8560978278ada600"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 3/10, Training Loss: 0.1092, Training Accuracy: 0.9655\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e5fab9b2e5d4e329407deaffac76d4b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 3/10, Validation Loss: 0.2270, Validation Accuracy: 0.9306\nEpoch 3/10, Group Accuracies:\n  male_0: 0.9330\n  male_1: 0.9102\n  female_0: 0.9344\n  female_1: 0.9054\n  LGBTQ_0: 0.9321\n  LGBTQ_1: 0.8854\n  christian_0: 0.9295\n  christian_1: 0.9407\n  muslim_0: 0.9322\n  muslim_1: 0.8981\n  other_religions_0: 0.9311\n  other_religions_1: 0.9087\n  black_0: 0.9330\n  black_1: 0.8674\n  white_0: 0.9339\n  white_1: 0.8811\nValidation WGA: 0.8674\nmedian:0.9302688030759954\nmean:0.9160052804016888\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "315cd888e7fc4b80959273be817be4f2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 4/10, Training Loss: 0.1007, Training Accuracy: 0.9691\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd43f6155d6c4583aa645c8856e243d2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 4/10, Validation Loss: 0.2672, Validation Accuracy: 0.9314\nEpoch 4/10, Group Accuracies:\n  male_0: 0.9341\n  male_1: 0.9085\n  female_0: 0.9349\n  female_1: 0.9080\n  LGBTQ_0: 0.9328\n  LGBTQ_1: 0.8888\n  christian_0: 0.9301\n  christian_1: 0.9429\n  muslim_0: 0.9328\n  muslim_1: 0.9033\n  other_religions_0: 0.9321\n  other_religions_1: 0.9016\n  black_0: 0.9337\n  black_1: 0.8723\n  white_0: 0.9347\n  white_1: 0.8821\nValidation WGA: 0.8723\nmedian:0.9310988750058462\nmean:0.9170451935384162\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e00867388cf449d81316e9a28608f0e"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 5/10, Training Loss: 0.0934, Training Accuracy: 0.9719\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a49430eb00741b182b82189e6ab01e7"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 5/10, Validation Loss: 0.2683, Validation Accuracy: 0.9298\nEpoch 5/10, Group Accuracies:\n  male_0: 0.9327\n  male_1: 0.9051\n  female_0: 0.9340\n  female_1: 0.9022\n  LGBTQ_0: 0.9311\n  LGBTQ_1: 0.8909\n  christian_0: 0.9285\n  christian_1: 0.9413\n  muslim_0: 0.9310\n  muslim_1: 0.9047\n  other_religions_0: 0.9307\n  other_religions_1: 0.8895\n  black_0: 0.9319\n  black_1: 0.8747\n  white_0: 0.9327\n  white_1: 0.8873\nValidation WGA: 0.8747\nmedian:0.9296201482753792\nmean:0.9155281204181197\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-head GLove_att - training it on whole data - but with a bigger glove embedding - wiki\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    metric.reset()\n",
        "\n",
        "    for x, y,idx,weights in tqdm(train_loader):\n",
        "        x, y = x.to(device), y.to(device).squeeze()\n",
        "        #print(weights)\n",
        "        weights=weights.to(device)\n",
        "        #print(x.shape,y.shape)\n",
        "        #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x).squeeze()\n",
        "        #print(outputs.shape)\n",
        "        #break\n",
        "        #print(f\"x shape: {x.shape}, y shape: {y.shape}, outputs shape: {outputs.shape}\")\n",
        "        #print(groups)\n",
        "        #break\n",
        "        #loss = custom_loss(outputs, y,groups)\n",
        "        loss = (F.binary_cross_entropy_with_logits(outputs,y, reduction='none') * weights ).mean()\n",
        "        loss.backward()\n",
        "        # Gradient clipping\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        #scheduler.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        #print(torch.sigmoid(outputs.squeeze()))\n",
        "        #print(y.int())\n",
        "        metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "    train_accuracy = metric.compute()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_train_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    metric.reset()\n",
        "    val_predictions = []\n",
        "    val_indices = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y,idx,weights in tqdm(val_loader):\n",
        "            x, y = x.to(device), y.to(device).squeeze()\n",
        "            #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "            outputs = model(x).squeeze()\n",
        "            val_loss += (F.binary_cross_entropy_with_logits(outputs, y, reduction='none') ).mean().item()\n",
        "            metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "            val_predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "            val_indices.extend(idx.numpy())\n",
        "\n",
        "    val_accuracy = metric.compute()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Format predictions for WGA calculation\n",
        "    val_pred_df = pd.DataFrame({'index': val_indices, 'pred': val_predictions}).set_index('index')\n",
        "\n",
        "    # Compute WGA\n",
        "    group_accuracies, wga = compute_group_accuracies(val_pred_df, val_loader.dataset.labels)  # Ensure val_metadata is defined and aligned\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Group Accuracies:\")\n",
        "    for group, accuracy in group_accuracies.items():\n",
        "        print(f\"  {group}: {accuracy:.4f}\")\n",
        "    print(f\"Validation WGA: {wga:.4f}\")\n",
        "\n",
        "    accuracies_list = [accuracy for group, accuracy in group_accuracies.items()]\n",
        "    median_accuracy = np.median(accuracies_list)\n",
        "    mean_accuracy = np.mean(accuracies_list)\n",
        "    print(f'median:{median_accuracy}')\n",
        "    print(f'mean:{mean_accuracy}')\n",
        "\n",
        "# Save the model if needed\n",
        "# torch.save(model.state_dict(), 'model_path.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-05T14:37:30.276592Z",
          "iopub.execute_input": "2024-02-05T14:37:30.276962Z",
          "iopub.status.idle": "2024-02-05T14:41:50.527803Z",
          "shell.execute_reply.started": "2024-02-05T14:37:30.276931Z",
          "shell.execute_reply": "2024-02-05T14:41:50.526538Z"
        },
        "trusted": true,
        "id": "AJnPi02o9bZv",
        "outputId": "c17c1ddc-ea3b-466e-8683-885969f1335c",
        "colab": {
          "referenced_widgets": [
            "e1c628561ecd4b6daf4fb5c90ac2728f",
            "40766ced20104846bb1a2b3b594529e4"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1c628561ecd4b6daf4fb5c90ac2728f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Training Loss: 0.0870, Training Accuracy: 0.9738\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40766ced20104846bb1a2b3b594529e4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Validation Loss: 0.2610, Validation Accuracy: 0.9296\nEpoch 1/10, Group Accuracies:\n  male_0: 0.9324\n  male_1: 0.9062\n  female_0: 0.9333\n  female_1: 0.9046\n  LGBTQ_0: 0.9310\n  LGBTQ_1: 0.8874\n  christian_0: 0.9288\n  christian_1: 0.9369\n  muslim_0: 0.9309\n  muslim_1: 0.9033\n  other_religions_0: 0.9301\n  other_religions_1: 0.9087\n  black_0: 0.9318\n  black_1: 0.8711\n  white_0: 0.9326\n  white_1: 0.8859\nValidation WGA: 0.8711\nmedian:0.929415111215445\nmean:0.9159354129203245\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-head GLove_att - training it on whole data - but with a bigger glove embedding - wiki\n",
        "for epoch in range(1):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    metric.reset()\n",
        "\n",
        "    for x, y,idx,weights in tqdm(train_loader):\n",
        "        x, y = x.to(device), y.to(device).squeeze()\n",
        "        #print(weights)\n",
        "        weights=weights.to(device)\n",
        "        #print(x.shape,y.shape)\n",
        "        #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x).squeeze()\n",
        "        #print(outputs.shape)\n",
        "        #break\n",
        "        #print(f\"x shape: {x.shape}, y shape: {y.shape}, outputs shape: {outputs.shape}\")\n",
        "        #print(groups)\n",
        "        #break\n",
        "        #loss = custom_loss(outputs, y,groups)\n",
        "        loss = (F.binary_cross_entropy_with_logits(outputs,y, reduction='none') * weights ).mean()\n",
        "        loss.backward()\n",
        "        # Gradient clipping\n",
        "        #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        #scheduler.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        #print(torch.sigmoid(outputs.squeeze()))\n",
        "        #print(y.int())\n",
        "        metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "    train_accuracy = metric.compute()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_train_loss/len(train_loader):.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0.0\n",
        "    metric.reset()\n",
        "    val_predictions = []\n",
        "    val_indices = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y,idx,weights in tqdm(val_loader):\n",
        "            x, y = x.to(device), y.to(device).squeeze()\n",
        "            #groups = [torch.tensor(group).to(device) for group in groups]\n",
        "            outputs = model(x).squeeze()\n",
        "            val_loss += (F.binary_cross_entropy_with_logits(outputs, y, reduction='none') ).mean().item()\n",
        "            metric.update(torch.sigmoid(outputs), y.int())\n",
        "\n",
        "            val_predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "            val_indices.extend(idx.numpy())\n",
        "\n",
        "    val_accuracy = metric.compute()\n",
        "    val_loss /= len(val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Format predictions for WGA calculation\n",
        "    val_pred_df = pd.DataFrame({'index': val_indices, 'pred': val_predictions}).set_index('index')\n",
        "\n",
        "    # Compute WGA\n",
        "    group_accuracies, wga = compute_group_accuracies(val_pred_df, val_loader.dataset.labels)  # Ensure val_metadata is defined and aligned\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Group Accuracies:\")\n",
        "    for group, accuracy in group_accuracies.items():\n",
        "        print(f\"  {group}: {accuracy:.4f}\")\n",
        "    print(f\"Validation WGA: {wga:.4f}\")\n",
        "\n",
        "    accuracies_list = [accuracy for group, accuracy in group_accuracies.items()]\n",
        "    median_accuracy = np.median(accuracies_list)\n",
        "    mean_accuracy = np.mean(accuracies_list)\n",
        "    print(f'median:{median_accuracy}')\n",
        "    print(f'mean:{mean_accuracy}')\n",
        "\n",
        "# Save the model if needed\n",
        "# torch.save(model.state_dict(), 'model_path.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-05T14:43:05.32678Z",
          "iopub.execute_input": "2024-02-05T14:43:05.327198Z",
          "iopub.status.idle": "2024-02-05T14:47:26.406942Z",
          "shell.execute_reply.started": "2024-02-05T14:43:05.327162Z",
          "shell.execute_reply": "2024-02-05T14:47:26.405602Z"
        },
        "trusted": true,
        "id": "j5BaTMoO9bZw",
        "outputId": "c64f3418-ce09-49d9-e9f9-9ce91efd0918",
        "colab": {
          "referenced_widgets": [
            "d155fee62838467b9888e4dfb4673cd2",
            "6b54c732da934b639df2ac3e2435d2f9"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/5143 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d155fee62838467b9888e4dfb4673cd2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Training Loss: 0.0818, Training Accuracy: 0.9758\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/706 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b54c732da934b639df2ac3e2435d2f9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Epoch 1/10, Validation Loss: 0.2907, Validation Accuracy: 0.9309\nEpoch 1/10, Group Accuracies:\n  male_0: 0.9336\n  male_1: 0.9085\n  female_0: 0.9350\n  female_1: 0.9038\n  LGBTQ_0: 0.9325\n  LGBTQ_1: 0.8840\n  christian_0: 0.9296\n  christian_1: 0.9426\n  muslim_0: 0.9323\n  muslim_1: 0.9028\n  other_religions_0: 0.9316\n  other_religions_1: 0.9026\n  black_0: 0.9334\n  black_1: 0.8668\n  white_0: 0.9337\n  white_1: 0.8898\nValidation WGA: 0.8668\nmedian:0.930603848885863\nmean:0.916421042585877\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model's state, optimizer's state, and scheduler's state to a file.\n",
        "torch.save({\n",
        "    'epoch': epoch,  # Current epoch number\n",
        "    'model_state_dict': model.module.state_dict(),  # State of the model\n",
        "    'optimizer_state_dict': optimizer.state_dict(),  # State of the optimizer\n",
        "    'loss': loss,  # Last recorded loss\n",
        "    'scheduler_state_dict': scheduler.state_dict()  # State of the scheduler\n",
        "}, 'glove_multi_head_attention_model_1.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-05T14:50:38.338651Z",
          "iopub.execute_input": "2024-02-05T14:50:38.339103Z",
          "iopub.status.idle": "2024-02-05T14:50:38.586465Z",
          "shell.execute_reply.started": "2024-02-05T14:50:38.339065Z",
          "shell.execute_reply": "2024-02-05T14:50:38.585559Z"
        },
        "trusted": true,
        "id": "eVjhoK3H9bZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load checkpoint\n",
        "checkpoint = torch.load('/kaggle/input/data-bal/glove_multi_head_attention_model_1.pth')\n",
        "\n",
        "# Adjust the keys\n",
        "state_dict = {f'module.{k}': v for k, v in checkpoint['model_state_dict'].items()}\n",
        "\n",
        "# Load the adjusted state dict\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:13:13.227325Z",
          "iopub.execute_input": "2024-02-06T09:13:13.227704Z",
          "iopub.status.idle": "2024-02-06T09:13:13.314066Z",
          "shell.execute_reply.started": "2024-02-06T09:13:13.227673Z",
          "shell.execute_reply": "2024-02-06T09:13:13.313052Z"
        },
        "trusted": true,
        "id": "hNlCnZCX9bZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iZ5xUBLq9bZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NVDsummH9bZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SWOhHhY9bZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, comments):\n",
        "        self.comments = comments\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        comment = torch.tensor(self.comments[idx], dtype=torch.long)\n",
        "        return comment\n",
        "\n",
        "# Create datasets\n",
        "test_dataset = TestDataset(X_test)  # Assuming train_labels is defined\n",
        "# Create data loaders\n",
        "batch_size = 32  # Define your batch size\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:13:31.508336Z",
          "iopub.execute_input": "2024-02-06T09:13:31.509062Z",
          "iopub.status.idle": "2024-02-06T09:13:31.515481Z",
          "shell.execute_reply.started": "2024-02-06T09:13:31.50903Z",
          "shell.execute_reply": "2024-02-06T09:13:31.514459Z"
        },
        "trusted": true,
        "id": "wC0iMBvL9bZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_predictions = []\n",
        "with torch.no_grad():\n",
        "    test_iterator = tqdm(test_loader, desc='Testing', dynamic_ncols=True)\n",
        "    for comments in test_iterator:\n",
        "\n",
        "        comments = comments.to(device)\n",
        "\n",
        "        outputs = model(comments)\n",
        "\n",
        "\n",
        "        probs = torch.sigmoid(outputs)  # Convert logits to probabilities\n",
        "        predicted_labels = (probs > 0.5).float()  # Convert probabilities to predicted class (0 or 1)\n",
        "\n",
        "        test_predictions.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    test_predictions = np.concatenate(test_predictions, axis=0)\n",
        "\n",
        "    predictions_df = pd.DataFrame({\n",
        "        'ID': list(test_data.index),  # This should align with the index of your 'y' DataFrame\n",
        "        'pred': test_predictions.squeeze()  # Make sure this is a 1D array\n",
        "            })"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:13:40.608909Z",
          "iopub.execute_input": "2024-02-06T09:13:40.609243Z",
          "iopub.status.idle": "2024-02-06T09:14:55.417763Z",
          "shell.execute_reply.started": "2024-02-06T09:13:40.609217Z",
          "shell.execute_reply": "2024-02-06T09:14:55.416935Z"
        },
        "trusted": true,
        "id": "n2a_p01l9bZy",
        "outputId": "4b944b6c-3170-432e-c5a0-e1b2837a3cf3",
        "colab": {
          "referenced_widgets": [
            "0548a05e3ac6416e9f10bd19244bfb95"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Testing:   0%|          | 0/4181 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0548a05e3ac6416e9f10bd19244bfb95"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['preds'] = predictions_df['pred']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:17:51.332256Z",
          "iopub.execute_input": "2024-02-06T09:17:51.332644Z",
          "iopub.status.idle": "2024-02-06T09:17:51.338294Z",
          "shell.execute_reply.started": "2024-02-06T09:17:51.332612Z",
          "shell.execute_reply": "2024-02-06T09:17:51.337323Z"
        },
        "trusted": true,
        "id": "tiqPHnhC9bZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:17:56.837625Z",
          "iopub.execute_input": "2024-02-06T09:17:56.838514Z",
          "iopub.status.idle": "2024-02-06T09:17:56.850946Z",
          "shell.execute_reply.started": "2024-02-06T09:17:56.838477Z",
          "shell.execute_reply": "2024-02-06T09:17:56.849998Z"
        },
        "trusted": true,
        "id": "Yi8qb-Cm9bZz",
        "outputId": "1f64987d-ccc5-49ec-ccde-2a5d3e2d963a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 74,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         index                                             string  preds\n0            0  oh yes   -   were those evil christian mission...    1.0\n1            1  he is considered a good candidate for a cyber ...    0.0\n2            2  lela  ,   you admit no records exist to suppor...    0.0\n3            3  I will take the iffy libertarian over the guy ...    1.0\n4            4  should not your handle be republic of uranus  ?      0.0\n...        ...                                                ...    ...\n133777  133777  is it better to be dead  ,   and broke  ?   al...    0.0\n133778  133778  when you say speaking in code  ,   you are add...    0.0\n133779  133779  at least twice trained law enforcement officer...    1.0\n133780  133780  I have not said this before  ,   but kizla you...    0.0\n133781  133781  the democrat party aided and abetted by it is ...    1.0\n\n[133782 rows x 3 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>string</th>\n      <th>preds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>oh yes   -   were those evil christian mission...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>he is considered a good candidate for a cyber ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>lela  ,   you admit no records exist to suppor...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>I will take the iffy libertarian over the guy ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>should not your handle be republic of uranus  ?</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>133777</th>\n      <td>133777</td>\n      <td>is it better to be dead  ,   and broke  ?   al...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133778</th>\n      <td>133778</td>\n      <td>when you say speaking in code  ,   you are add...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133779</th>\n      <td>133779</td>\n      <td>at least twice trained law enforcement officer...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>133780</th>\n      <td>133780</td>\n      <td>I have not said this before  ,   but kizla you...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133781</th>\n      <td>133781</td>\n      <td>the democrat party aided and abetted by it is ...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>133782 rows × 3 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:19:00.805113Z",
          "iopub.execute_input": "2024-02-06T09:19:00.805814Z",
          "iopub.status.idle": "2024-02-06T09:19:00.816437Z",
          "shell.execute_reply.started": "2024-02-06T09:19:00.805777Z",
          "shell.execute_reply": "2024-02-06T09:19:00.815598Z"
        },
        "trusted": true,
        "id": "sdLEl9k_9bZz",
        "outputId": "2d5c22e7-de6d-4608-9363-c85a9ed12ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 77,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            ID  pred\n0            0   1.0\n1            1   0.0\n2            2   0.0\n3            3   1.0\n4            4   0.0\n...        ...   ...\n133777  133777   0.0\n133778  133778   0.0\n133779  133779   1.0\n133780  133780   0.0\n133781  133781   1.0\n\n[133782 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>133777</th>\n      <td>133777</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133778</th>\n      <td>133778</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133779</th>\n      <td>133779</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>133780</th>\n      <td>133780</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>133781</th>\n      <td>133781</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>133782 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df.to_csv('weighted_multi_head_attention.csv',index = False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-06T09:18:45.68012Z",
          "iopub.execute_input": "2024-02-06T09:18:45.680836Z",
          "iopub.status.idle": "2024-02-06T09:18:45.87644Z",
          "shell.execute_reply.started": "2024-02-06T09:18:45.680796Z",
          "shell.execute_reply": "2024-02-06T09:18:45.87562Z"
        },
        "trusted": true,
        "id": "zrN6E5ja9bZz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}